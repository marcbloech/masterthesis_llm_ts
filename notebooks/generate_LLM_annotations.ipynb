{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating SALSA-Annotations with LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import csv\n",
    "from anthropic import Anthropic\n",
    "from openai import AzureOpenAI, OpenAI\n",
    "import replicate\n",
    "from anthropic import Anthropic\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "from helper_functions import get_api_type, QUALITY_EXPANDED_MAPPING\n",
    "\n",
    "import en_core_web_sm\n",
    "\n",
    "import concurrent.futures\n",
    "import threading\n",
    "\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_key = \"INSERT_KEY_HERE\"\n",
    "anthropic_key = \"INSERT_KEY_HERE\"\n",
    "replicate_key = \"INSERT_KEY_HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup AI APIs\n",
    "\n",
    "from anthropic import Anthropic\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "\n",
    "LMstudio_client = OpenAI(\n",
    "    base_url=\"http://localhost:1234/v1\",\n",
    "    api_key=\"lm-studio\"\n",
    ")\n",
    "model_gpt =\"gpt-4o-2024-08-06\"\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "openai_client = AzureOpenAI(\n",
    "        azure_endpoint = \"YOUR_URL_HERE\", \n",
    "        api_key=azure_key,  \n",
    "        api_version=\"2024-08-01-preview\"\n",
    "        )\n",
    "\n",
    "\n",
    "clientAnthropic = Anthropic(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"CLAUDE_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Edit Identification Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System prompt: You are a helpful assistant and expert in text simplification annotations that can identify the changes between two sentences and annotate them using the specified framework.\n",
      "Salsa prompt: You are tasked with annotating sentence pairs from a text simplification dataset. \n",
      "Your goal is to identify and categorize the edits made to simplify the original sentence, as well as to note any errors introduced in the process. \n",
      "Follow these instructions carefully:\n",
      "\n",
      "1. You will be presented with two sentences:\n",
      "<original_sentence>\n",
      "{{ORIGINAL_SENTENCE}}\n",
      "</original_sentence>\n",
      "\n",
      "<simplified_sentence>\n",
      "{{SIMPLIFIED_SENTENCE}}\n",
      "</simplified_sentence>\n",
      "\n",
      "2. Analyze the differences between the original and simplified sentences, focusing on the following categories of edits:\n",
      "\n",
      "a) Phrase-level Edits:\n",
      "   - Deletion Edits\n",
      "   - Insertion Edits\n",
      "   - Substitution Edits\n",
      "\n",
      "b) Sentence-level Edits:\n",
      "   - Splitting Edits\n",
      "   - Reordering Edits\n",
      "   - Structural Edits\n",
      "\n",
      "When identifying edits, focus on the smallest possible unit: Don't indicate a whole sentence as a substitution if one word has changed, but only that word.\n",
      "\n",
      "\n",
      "3. For each edit identified, determine the type of change and its direction (posive, neutral, or negative):\n",
      "   - Deletion:\n",
      "       - Insignificant Deletion: Did it remove INSIGNIFICANT information (thus improving the sentence)?\n",
      "       - Trivial Deletion: Was it a trivial deletion?\n",
      "       - Significant Deletion: Did it remove SIGNIFICANT information (deleting necessary and relevant content to the sentence's central meaning)?\n",
      "   - Insertion:\n",
      "        Positive Insertions:\n",
      "        - Elaboration: Adds meaningful, relevant, and correct information\n",
      "        - Trivial Insertion: Adds minor modifications that don't significantly affect meaning or complexity\n",
      "        Negative Insertions:\n",
      "        - Repetition: Adds information that simply repeats knowledge already contained in the sentence\n",
      "        - Irrelevant: Adds information unrelated to the main idea of the sentence\n",
      "        - Contradiction: Adds information that contradicts the original sentence\n",
      "        - Factual Error: Introduces externally verifiable incorrect information\n",
      "\n",
      "   - Substitution (Attention: Differing sub-types depending on the type of substitution):\n",
      "        - same meaning:  Swaps complex words with equivalent, simpler alternatives, while retaining the same meaning\n",
      "        - less information: Deleting insignificant information (good), trivial information, or significant information (bad).\n",
      "        - more information: --> refer to Insertion types (Elaboration, etc)\n",
      "        - different information: information was removed from the phrase and replaced with new information\n",
      "\n",
      "   - Splitting (subdiving a sentence into smaller sentencens).\n",
      "        - Negative Splitting: Split at an inappropriate location or interrupted the flow of idea\n",
      "        - Neutral Splitting: Divides the sentence without significantly affecting readability or meaning\n",
      "        - Positive Splitting: Improves clarity by separating independent pieces of information into distinct sentences\n",
      "\n",
      "   - Reordering:\n",
      "        - Word-level Reorder: Reorganizes modifiers within a phrase\n",
      "            - Negative: Presented a new word order with less clarity within a clause\n",
      "            - Neutral: Reorders words without significantly affecting clarity or meaning\n",
      "            - Positive: Presents a new word order that improves clarity within a clause\n",
      "        - Component-level Reorder: Moves clauses or content across a sentence\n",
      "            - Negative: Presents a new clausal order that reduces clarity or disrupts the logical flow of ideas\n",
      "            - Neutral: Reorders components without significantly affecting clarity or meaning\n",
      "            - Positive: Presents a new clausal order that improves clarity or the logical flow of ideas\n",
      "\n",
      "   - Structural: \n",
      "        - Voice Change: Changes between active and passive voice\n",
      "        - Part-of-Speech Change: Modifies words' derivation or inflection\n",
      "        - Tense Change: Modifies verb modality or tense\n",
      "        - Grammatical Number Change: Changes between singular and plural or generic and specific\n",
      "        - Clausal Change: Modifies predicate structure\n",
      "    Each type of structural change has either a negative, neutral, or positive impact, just like the other edit types.\n",
      "\n",
      "\n",
      "4. For each categorized edit, rate its' severity as a number from 1 to 3:\n",
      "\n",
      "   Severity levels for negative changes:\n",
      "    - 1: low (changes, but sentence retains central meaning)\n",
      "    - 2: medium (significant changes, but sentence retains entral meaning)\n",
      "    - 3: high (significant changes, changing or removing the sentence's central meaning or information)\n",
      "    Severity levels for positive changes:\n",
      "    - 1: low (slight improvement in readibility/understandability)\n",
      "    - 2: medium (some improvement in improving a sentence's understandability)\n",
      "    - 3: high (significant changes in improving a sentence's understandability, while retaining it's core meaning)\n",
      "\n",
      "\n",
      "4. Look for potential errors in the simplification:\n",
      "   - Coreference Error\n",
      "   - Grammar & Fluency Errors\n",
      "\n",
      "5. Use a <scratchpad> section to think through your analysis before providing the final annotation. \n",
      "In the scratchpad, list out the edits you've identified and any potential errors.\n",
      "\n",
      "Provide your final annotation in the following JSON format:\n",
      "\n",
      "<annotation>\n",
      "[\n",
      "  {\n",
      "    \"source\": \"{{ORIGINAL_SENTENCE}}\",\n",
      "    \"target\": \"{{SIMPLIFIED_SENTENCE}}\",\n",
      "    \"metadata\": {\n",
      "      \"annotator\": \"\",\n",
      "      \"system\": \"\"\n",
      "    },\n",
      "    \"edits\": [\n",
      "      {\n",
      "        \"id\": 1,\n",
      "        \"category\": \"deletion|insertion|substitution|splitting|reordering|structural\",\n",
      "        \"input_idx\": [[start_index, end_index IF APPLICABLE]],\n",
      "        \"output_idx\": [[start_index, end_index IF APPLICABLE]],\n",
      "        \"annotation\": {\n",
      "          \"edit_type\": {\n",
      "            \"val\": \"good_deletion|bad_deletion|elaboration|repetition|irrelevant|contradiction|factual_error|same_meaning|less_information|more_information|different_information|negative_splitting|neutral_splitting|positive_splitting|word_level_reorder|component_level_reorder|voice_change|part_of_speech_change|tense_change|grammatical_number_change|clausal_change\",\n",
      "            \"severity\": 1|2|3\n",
      "          },\n",
      "          \"coreference\": \"yes|no\",\n",
      "          \"grammar_error\": \"yes|no\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n",
      "</annotation>\n",
      "For each edit, provide an \"id\" (starting from 1), \"category\" (the main edit type), \"input_idx\" (the indices of the affected words in the original sentence), and detailed \"annotation\" information including the specific edit type, severity, and any errors.\n",
      "Try to avoid overlapping edits, meaning a given word should ideally only be present in one identified edit and edits should not overlap.\n",
      "Remember that edits can overlap. Be thorough in your analysis and provide clear explanations for each annotation. Ensure that your JSON is properly formatted and includes all necessary information for each edit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read in prompt files (txt)\n",
    "SYSTEM_file_name_to_use = \"system_prompt_annotations.txt\"\n",
    "PROMPT_file_name_to_use = \"salsa_prompt_instructions.txt\"\n",
    "\n",
    "system_prompt_import = open(f\"prompts_LLM_annotations/{SYSTEM_file_name_to_use}\", \"r\").read()\n",
    "print(f\"System prompt: {system_prompt_import}\")\n",
    "\n",
    "salsa_prompt_import = open(f\"prompts_LLM_annotations/{PROMPT_file_name_to_use}\", \"r\").read()\n",
    "print(f\"Salsa prompt: {salsa_prompt_import}\")\n",
    "\n",
    "#response_format_import = open(\"prompts_LLM_annotations/response_format_annotations.txt\", \"r\").read()\n",
    "#print(f\"Response format: {response_format_import}\")\n",
    "\n",
    "# instruction prompt about SALSA Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': 'Widespread blackouts are reported in Western Ukraine as Russian forces launch another wave of cruise missile strikes, including the city of Lviv which has experienced a total blackout.',\n",
       "  'target': 'Widespread blackouts are reported in Western Ukraine as Russian forces launch another wave of cruise missile strikes.',\n",
       "  'metadata': {'annotator': 'annotator_1', 'system': 'new-wiki-1/T5-11B'},\n",
       "  'edits': [{'id': 1,\n",
       "    'category': 'deletion',\n",
       "    'input_idx': [[17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]],\n",
       "    'annotation': {'deletion_type': {'val': 'bad_deletion',\n",
       "      'bad_deletion': 'minor'},\n",
       "     'coreference': 'no',\n",
       "     'grammar_error': 'no'}}]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# few-shot examples of SALSA annotations\n",
    "prompt_few_shots_intro = \"Here are three examples of how to annotate a sentence pair:\"\n",
    "\n",
    "# read in few-shot examples JSON file (indices have been converted to words from original character-based indices)\n",
    "with open(\"prompts_LLM_annotations/example_data_SALSA_official_WordIndices.json\", 'r') as file:\n",
    "    few_shot_examples = json.load(file)\n",
    "\n",
    "def generate_n_random_examples(n):\n",
    "    return random.sample(few_shot_examples, n)\n",
    "\n",
    "fewshot_test = generate_n_random_examples(1)\n",
    "fewshot_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_insert_sentence_pair(sentence1, sentence2):\n",
    "    return f\"\"\"\n",
    " Here is the sentence pair you need to annotate:\n",
    "<original_sentence>{sentence1}</original_sentence>\n",
    "<simplified_sentence>{sentence2}</simplified_sentence>\n",
    "\n",
    "And here is the index map for all words in the original sentence:\n",
    "<index_map>{generate_word_index_map_simple(sentence1)}</index_map>\n",
    "\n",
    "And here is the index map for all words in the simplified sentence:\n",
    "<index_map>{generate_word_index_map_simple(sentence2)}</index_map>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System prompt: You are a helpful assistant and expert in text simplification annotations that can identify the changes between two sentences and annotate them using the specified framework.\n",
      "Salsa prompt: You are an expert text simplification analyst using the SALSA framework for a research project. \n",
      "Your task is to analyze the differences between an original sentence and its simplified version. Utmost careful work is paramount here.\n",
      "\n",
      "You are first given some information on the SALSA Framework for Text Simplification Annotations:\n",
      "<SALSA_Information>\n",
      "The SALSA (Structured Annotation for Linguistic Simplification Analysis) Framework is a comprehensive method for evaluating text simplifications. \n",
      "It provides a structured approach to annotating and analyzing changes made between an original text and its simplified version.\n",
      "\n",
      "SALSA recognizes 6 primary types of edits:\n",
      "Deletion, Insertion, Substitution, Splitting, Reordering, and Structural Changes.\n",
      "\n",
      "- Deletion:\n",
      "       - Insignificant Deletion: Did it remove INSIGNIFICANT information (thus improving the sentence)? Example: \"Like so many hyped books before it, The Midnight Library excited me and gave me pause.\" → \"The Midnight Library excited me and gave me pause.\"\n",
      "       - Trivial Deletion: Was it a trivial deletion?\n",
      "       - Significant Deletion: Did it remove SIGNIFICANT information (deleting necessary and relevant content to the sentence's central meaning)? Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many chemicals are increasing in abundance in the lower troposphere.\" (Removing \"volatile organic\")\n",
      "   - Insertion:\n",
      "        Positive Insertions:\n",
      "        - Elaboration: Adds meaningful, relevant, and correct information. Example: \"Many volatile organic chemicals are increasing...\" → \"Many volatile organic chemicals, which harm our environment, are increasing...\"\n",
      "        - Trivial Insertion: Adds minor modifications that don't significantly affect meaning or complexity. Example: \"How big is the family you cook for?\" → \"How big is the family THAT you cook for?\"\n",
      "        Negative Insertions:\n",
      "        - Repetition: Adds information that simply repeats knowledge already contained in the sentence. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals, which are chemicals, are increasing in abundance in the lower troposphere.\"\n",
      "        - Irrelevant: Adds information unrelated to the main idea of the sentence. Example: \"Many volatile organic chemicals are increasing...\" → \"Many volatile organic chemicals, unlike low vapor pressure chemicals, are increasing...\"\n",
      "        - Contradiction: Adds information that contradicts the original sentence. Example: \"Many volatile organic chemicals are increasing...\" → \"Many volatile organic chemicals, which are decreasing in our troposphere, are increasing...\"\n",
      "        - Factual Error: Introduces externally verifiable incorrect information. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals are increasing in abundance in the lower troposphere when they decide to.\"\n",
      "\n",
      "   - Substitution (Attention: Differing sub-types depending on the type of substitution):\n",
      "        - same meaning:  Swaps complex words with equivalent, simpler alternatives, while retaining the same meaning. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals are being seen more in the lower troposphere.\"\n",
      "        - less information: Deleting insignificant information (good), trivial information, or significant information (bad). Example: Like Deletion\n",
      "        - more information: --> refer to Insertion types (Elaboration, etc). Example: Like Insertion.\n",
      "        - different information: information was removed from the phrase and replaced with new information. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals are decreasing in abundance in the lower troposphere.\"\n",
      "\n",
      "   - Splitting (subdiving a sentence into smaller sentencens).\n",
      "        - Negative Splitting: Split at an inappropriate location or interrupted the flow of idea. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals are increasing. They are increasing in abundance in the lower troposphere.\"\n",
      "        - Neutral Splitting: Divides the sentence without significantly affecting readability or meaning\n",
      "        - Positive Splitting: Improves clarity by separating independent pieces of information into distinct sentences. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals are increasing. They are found in abundance in the lower troposphere.\"\n",
      "\n",
      "   - Reordering:\n",
      "        - Word-level Reorder: Reorganizes modifiers within a phrase\n",
      "            - Negative: Presented a new word order with less clarity within a clause\n",
      "            - Neutral: Reorders words without significantly affecting clarity or meaning\n",
      "            - Positive: Presents a new word order that improves clarity within a clause. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many organic volatile chemicals are increasing in abundance in the lower troposphere.\"\n",
      "        - Component-level Reorder: Moves clauses or content across a sentence\n",
      "            - Negative: Presents a new clausal order that reduces clarity or disrupts the logical flow of ideas\n",
      "            - Neutral: Reorders components without significantly affecting clarity or meaning\n",
      "            - Positive: Presents a new clausal order that improves clarity or the logical flow of ideas. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"In the lower troposphere, many volatile organic chemicals are increasing in abundance.\"\n",
      "\n",
      "   - Structural: \n",
      "        - Voice Change: Changes between active and passive voice. Example: \"Elevation is not primarily considered by the system.\" → \"The system does not primarily consider elevation.\"\n",
      "        - Part-of-Speech Change: Modifies words' derivation or inflection. Example: \"The ability to capture nature scenes has been improving...\" → \"The ability to capture nature scenes has seen improvement...\" Additional example: \"The protesters turned violent when...\" → \"The violent protesters...\"\n",
      "        - Tense Change: Modifies verb modality or tense. \"The governor told reporters he had overseen a productive conversation.\" → \"The governor oversaw a productive conversation.\"\n",
      "        - Grammatical Number Change: Changes between singular and plural or generic and specific. Example: \"Victor had scored that goal against the US in 2011, and another in 2012.\" → \"Victor had scored those goals in 2011 and 2012.\"\n",
      "        - Clausal Change: Modifies predicate structure. Example: \"Donaldson attempted to speak clearly and he was successful.\" → \"Donaldson attempted to speak clearly and successfully.\" Additional example: \"Although it was raining outside, Jobs continued work in his garage.\" → \"Outside it was raining and Jobs continued work in his garage.\"\n",
      "\n",
      "For each edit, we rate its severity as a number from 1 to 3:\n",
      "   Severity levels for negative changes:\n",
      "    - 1: minor (changes, but sentence retains central meaning)\n",
      "    - 2: somewhat (significant changes, but sentence retains central meaning)\n",
      "    - 3: a lot (significant changes, changing or removing the sentence's central meaning or information)\n",
      "    Severity levels for positive changes:\n",
      "    - 1: minor (slight improvement in readibility/understandability)\n",
      "    - 2: somewhat (some improvement in improving a sentence's understandability)\n",
      "    - 3: a lot (significant changes in improving a sentence's understandability, while retaining it's core meaning)\n",
      "\n",
      "In conclusion, the SALSA Framework offers a comprehensive and structured approach to analyzing text simplifications. \n",
      "By breaking down edits into specific categories (Deletion, Insertion, Substitution, Reordering, Splitting, and Structural Change) and assessing their impact on information content and readability, \n",
      "it provides a powerful tool for evaluating and improving simplification efforts.\n",
      "</SALSA_Information>\n",
      "\n",
      "Now with this knowledge, follow these steps carefully:\n",
      "\n",
      "<instructions>\n",
      "1. Input: You will be presented with two sentences:\n",
      "<original_sentence>\n",
      "{{ORIGINAL_SENTENCE}}\n",
      "</original_sentence>\n",
      "\n",
      "<simplified_sentence>\n",
      "{{SIMPLIFIED_SENTENCE}}\n",
      "</simplified_sentence>\n",
      "\n",
      "2. Identify Changes:\n",
      "List all changes you observe between the original and simplified sentences. \n",
      "For each change, specify the affected words (using their indexes) \n",
      "Important: You are given an index map of the words, indicating the position of each word. Use the numeric indices to mark which words are affected by an edit.\n",
      "List them all (including their indices) in a <identified_changes> section.\n",
      "Important: Try to avoid overlapping edits, meaning a given word should ideally only be present in one identified edit and edits should not overlap.\n",
      "And try to keep an edit to its smallest possible size (e.g., splitting up bigger edits into their components when sensible instead of marking half of a sentence as one big edit).\n",
      "\n",
      "3. Categorize Changes:\n",
      "For each change you identified, categorize it according to the SALSA framework. \n",
      "Determine if it's a Deletion, Insertion, Substitution, Reordering, Splitting, or Structural change. \n",
      "List them all in a <categorized_changes> section.\n",
      "\n",
      "4. Analyze Impact and rate Severity:\n",
      "For each categorized change, analyze its impact and severity.\n",
      "First, determine if it's positive, neutral, or negative according to the SALSA framework criteria and rate the severity of each change on a scale of 1-3, where 1 is low impact and 3 is high impact. Justify each rating based on the SALSA framework guidelines.\n",
      "List them all in a <rating_changes> section.\n",
      "\n",
      "5. Detect Errors:\n",
      "Examine the simplified sentence for any potential errors, such as coreference issues or grammar and fluency problems. \n",
      "List any errors you find in a <errors> section.\n",
      "\n",
      "6. Generate JSON Structure:\n",
      "Based on your analysis and all the information you created, create a JSON structure that follows the format of the examples supplied below. \n",
      "Only fill out the \"edits\" section of it (no need to re-state the source and target sentences, and the metadata).\n",
      "Put this into a <JSON_OUTPUT> section.\n",
      "\n",
      "7. Review and Refine:\n",
      "Review the JSON structure you've created. Ensure all changes are accurately represented and all required fields are present. \n",
      "Try avoiding overlapping edits.\n",
      "Use the examples below and the SALSA guidelines as help. Make any necessary adjustments.\n",
      "</instructions>\n",
      "\n",
      "Example output JSON files:\n",
      "<examples>\n",
      "<TODO INSERT EXAMPLE>\n",
      "</examples>\n",
      "\n",
      "Remember to be thorough in your analysis and think step by step. Verify your JSON file at the end, to validate its properly formatted or change it if necessary.\n"
     ]
    }
   ],
   "source": [
    "# read in prompt files (txt)\n",
    "system_prompt_import = open(\"prompts_LLM_annotations/system_prompt_annotations.txt\", \"r\").read()\n",
    "print(f\"System prompt: {system_prompt_import}\")\n",
    "\n",
    "salsa_prompt_COT_import = open(\"prompts_LLM_annotations/SALSA_Prompt_CoT_V01.txt\", \"r\").read()\n",
    "print(f\"Salsa prompt: {salsa_prompt_COT_import}\")\n",
    "\n",
    "#response_format_import = open(\"prompts_LLM_annotations/response_format_annotations.txt\", \"r\").read()\n",
    "#print(f\"Response format: {response_format_import}\")\n",
    "\n",
    "# instruction prompt about SALSA Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"source\": \"The last president to run after leaving office was Theodore Roosevelt, who came in second in the 1912 election as the presidential nominee of the Progressive Party, although Herbert Hoover did briefly seek the Republican presidential nomination at several national conventions subsequent to leaving office in 1933.\", \"target\": \"The last president to run after leaving office was Theodore Roosevelt.\", \"metadata\": {\"annotator\": \"annotator_2\", \"system\": \"new-wiki-1/T5-3B\"}, \"edits\": [{\"id\": 1, \"category\": \"deletion\", \"input_idx\": [[11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46]], \"annotation\": {\"deletion_type\": {\"val\": \"bad_deletion\", \"bad_deletion\": \"a lot\"}, \"coreference\": \"no\", \"grammar_error\": \"no\"}}]}\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in few-shot examples JSON file\n",
    "with open(\"prompts_LLM_annotations/example_data_SALSA_official_WordIndices.json\", 'r') as file:\n",
    "    few_shot_examples = json.load(file)\n",
    "\n",
    "def generate_n_random_examples(n):\n",
    "    # add line breaks between each example\n",
    "    examples_string = \"\"\n",
    "    for example in random.sample(few_shot_examples, n):\n",
    "        examples_string += json.dumps(example) + \"\\n\\n\"\n",
    "    return examples_string\n",
    "\n",
    "fewshot_test = generate_n_random_examples(1)\n",
    "fewshot_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_insert_sentence_pair(sentence1, sentence2):\n",
    "    return f\"\"\"\n",
    "    \n",
    " Here is the sentence pair you need to annotate:\n",
    "<original_sentence>{sentence1}</original_sentence>\n",
    "<simplified_sentence>{sentence2}</simplified_sentence>\n",
    "\n",
    "And here is the index map for all words in the original sentence:\n",
    "<index_map>{generate_word_index_map_simple(sentence1)}</index_map>\n",
    "\n",
    "And here is the index map for all words in the simplified sentence:\n",
    "<index_map>{generate_word_index_map_simple(sentence2)}</index_map>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def word_indices_to_char_indices(sentence, word_indices):\n",
    "    char_index_map = generate_word_index_map(sentence)\n",
    "    words = sentence.split()\n",
    "    \n",
    "    if not word_indices:\n",
    "        return None\n",
    "    \n",
    "    start_word = words[word_indices[0]]\n",
    "    end_word = words[word_indices[-1]]\n",
    "    \n",
    "    start_char = char_index_map[start_word][0]\n",
    "    end_char = char_index_map[end_word][1]\n",
    "    \n",
    "    return [start_char, end_char]\n",
    "\n",
    "def convert_indices_in_edit(edit, source_sentence, target_sentence):\n",
    "    #print(f\"Debug: edit: {edit}\")\n",
    "    if 'input_idx' in edit:\n",
    "        edit['input_idx'] = [word_indices_to_char_indices(source_sentence, idx) for idx in edit['input_idx']]\n",
    "        #print(f\"Debug: input_idx: {edit['input_idx']}\")\n",
    "    if 'output_idx' in edit:\n",
    "        edit['output_idx'] = [word_indices_to_char_indices(target_sentence, idx) for idx in edit['output_idx']]\n",
    "        #print(f\"Debug: output_idx: {edit['output_idx']}\")\n",
    "    if 'constituent_edits' in edit:\n",
    "        for constituent in edit['constituent_edits']:\n",
    "            if 'input_idx' in constituent:\n",
    "                constituent['input_idx'] = [word_indices_to_char_indices(source_sentence, idx) for idx in constituent['input_idx']]\n",
    "            if 'output_idx' in constituent:\n",
    "                constituent['output_idx'] = [word_indices_to_char_indices(target_sentence, idx) for idx in constituent['output_idx']]\n",
    "    return edit\n",
    "\n",
    "def assemble_JSON_output(response_text, original_sentence, simplified_sentence):\n",
    "    # Extract the JSON content from the response\n",
    "    json_match = re.search(r'```json\\s*(\\{.*?\\})\\s*```', response_text, re.DOTALL)\n",
    "    if json_match:\n",
    "        print(\"DEBUG: found json block\")\n",
    "        json_content = json_match.group(1)\n",
    "    else:\n",
    "        print(\"DEBUG: no json block found, using entire <JSON_OUTPUT>\")\n",
    "        # If no JSON block is found, use the entire <JSON_OUTPUT> content\n",
    "        json_content = response_text.split(\"<JSON_OUTPUT>\")[1].split(\"</JSON_OUTPUT>\")[0].strip()\n",
    "    \n",
    "    # Parse the extracted JSON\n",
    "    try:\n",
    "        edits = json.loads(json_content)[\"edits\"]\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error parsing JSON. Content:\", json_content)\n",
    "        raise\n",
    "    \n",
    "    # Convert word indices to character indices\n",
    "    edits = [convert_indices_in_edit(edit, original_sentence, simplified_sentence) for edit in edits]\n",
    "    \n",
    "    # Assemble the full JSON output\n",
    "    full_output = {\n",
    "        \"source\": original_sentence,\n",
    "        \"target\": simplified_sentence,\n",
    "        \"metadata\": \"\",  # You can add metadata if needed\n",
    "        \"edits\": edits\n",
    "    }\n",
    "    \n",
    "    # Return the assembled JSON as a Python dictionary\n",
    "    return full_output\n",
    "\n",
    "# Usage\n",
    "# assembled_output = assemble_JSON_output(response_extracted, original_sentence_testing, simplified_sentence_testing)\n",
    "# print(assembled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first draft for data model\n",
    "from typing import List, Dict, Any, Optional, Union, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class DeletionType(BaseModel):\n",
    "    val: str\n",
    "    good_deletion: Optional[str]\n",
    "    bad_deletion: Optional[str]\n",
    "\n",
    "class DeletionAnnotation(BaseModel):\n",
    "    deletion_type: DeletionType\n",
    "    coreference: str\n",
    "    grammar_error: str\n",
    "\n",
    "class SubstitutionAnnotation(BaseModel):\n",
    "    substitution_info_change: Dict[str, Union[str, Dict[str, Union[str, Dict[str, str]]]]]\n",
    "    grammar_error: str\n",
    "\n",
    "class InsertionAnnotation(BaseModel):\n",
    "    insertion_type: Dict[str, Union[str, Dict[str, Union[str, Dict[str, str]]]]]\n",
    "    grammar_error: str\n",
    "\n",
    "class ReorderAnnotation(BaseModel):\n",
    "    reorder_level: Dict[str, Union[str, Dict[str, Union[str, Dict[str, str]]]]]\n",
    "    grammar_error: str\n",
    "\n",
    "class StructureAnnotation(BaseModel):\n",
    "    structure_type: Dict[str, str]\n",
    "    impact: Dict[str, Union[str, Dict[str, str]]]\n",
    "    grammar_error: str\n",
    "\n",
    "class SplitAnnotation(BaseModel):\n",
    "    impact: Dict[str, Union[str, Dict[str, str]]]\n",
    "    grammar_error: str\n",
    "\n",
    "class ConstituentEdit(BaseModel):\n",
    "    id: int\n",
    "    category: str\n",
    "    input_idx: Optional[List[Union[str, List[str]]]]\n",
    "    output_idx: Optional[List[Union[str, List[str]]]]\n",
    "\n",
    "# Define allowed categories\n",
    "EditCategory = Literal[\n",
    "    'deletion',\n",
    "    'substitution', \n",
    "    'insertion',\n",
    "    'reorder',\n",
    "    'structure',\n",
    "    'split'\n",
    "]\n",
    "\n",
    "class Edit(BaseModel):\n",
    "    category: EditCategory  # Only allows the predefined values\n",
    "    id: int\n",
    "    annotation: Union[\n",
    "        DeletionAnnotation,\n",
    "        SubstitutionAnnotation,\n",
    "        InsertionAnnotation,\n",
    "        ReorderAnnotation,\n",
    "        StructureAnnotation,\n",
    "        SplitAnnotation\n",
    "    ]\n",
    "    input_idx: Optional[List[List[int]]]\n",
    "    output_idx: Optional[List[List[int]]]\n",
    "    constituent_edits: Optional[List[ConstituentEdit]]\n",
    "\n",
    "# New main data model that includes source, target, and metadata\n",
    "class DataModel(BaseModel):\n",
    "    source: str = Field(description=\"The original complex sentence\")\n",
    "    target: str = Field(description=\"The simplified sentence\")\n",
    "    metadata: Dict[str, str] = Field(description=\"Metadata about the annotation, including annotator and system\")\n",
    "    edits: List[Edit] = Field(description=\"List of simplification edits\")\n",
    "    thresh_id: Optional[int] = Field(description=\" ID for the annotation - leave empty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Complex Format (JSON) - Also for Taxonomy Validation\n",
    "\n",
    "If we cannot Heineman's (somewhat intransparently organized) schema, can we replicate the final data we are extracting from it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "openai_client = AzureOpenAI(\n",
    "        azure_endpoint = \"INSERT_HERE\", \n",
    "        api_key=\"YOUR_KEY\",  \n",
    "        api_version=\"2024-08-01-preview\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "SentUID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Target",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Input Text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Output Text",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Edit Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Quality",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Significance",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "de2fa8c8-94a9-4c23-a55b-24b1e6e9aaf6",
       "rows": [
        [
         "0",
         "SALSA_EXAMPLES_001_SALSA_EXAMPLES",
         "Further important aspects of Fungi in Art relate to preservation of artworks from fungal decay and contamination, as well as initiatives fostering and supporting works able to stimulate dialogues between mycologists (fungal researchers), artists, and society (as for example from the 'Massee Art Grant' by the British Mycological Society or works encouraged and supported by the Fungi Foundation).",
         "An important aspect of Fungi in Art is the protection of artwork from fungal damage. || Another important aspect is to make sure mycologists, artists, and society are all on the same page.",
         "(as for example from the 'Massee Art Grant' by the British Mycological Society or works encouraged and supported by the Fungi Foundation).",
         null,
         "deletion",
         "good",
         "major"
        ],
        [
         "1",
         "SALSA_EXAMPLES_001_SALSA_EXAMPLES",
         "Further important aspects of Fungi in Art relate to preservation of artworks from fungal decay and contamination, as well as initiatives fostering and supporting works able to stimulate dialogues between mycologists (fungal researchers), artists, and society (as for example from the 'Massee Art Grant' by the British Mycological Society or works encouraged and supported by the Fungi Foundation).",
         "An important aspect of Fungi in Art is the protection of artwork from fungal damage. || Another important aspect is to make sure mycologists, artists, and society are all on the same page.",
         "(fungal researchers),",
         null,
         "deletion",
         "bad",
         "minor"
        ],
        [
         "2",
         "SALSA_EXAMPLES_001_SALSA_EXAMPLES",
         "Further important aspects of Fungi in Art relate to preservation of artworks from fungal decay and contamination, as well as initiatives fostering and supporting works able to stimulate dialogues between mycologists (fungal researchers), artists, and society (as for example from the 'Massee Art Grant' by the British Mycological Society or works encouraged and supported by the Fungi Foundation).",
         "An important aspect of Fungi in Art is the protection of artwork from fungal damage. || Another important aspect is to make sure mycologists, artists, and society are all on the same page.",
         "and contamination,",
         null,
         "deletion",
         "good",
         "medium"
        ],
        [
         "3",
         "SALSA_EXAMPLES_001_SALSA_EXAMPLES",
         "Further important aspects of Fungi in Art relate to preservation of artworks from fungal decay and contamination, as well as initiatives fostering and supporting works able to stimulate dialogues between mycologists (fungal researchers), artists, and society (as for example from the 'Massee Art Grant' by the British Mycological Society or works encouraged and supported by the Fungi Foundation).",
         "An important aspect of Fungi in Art is the protection of artwork from fungal damage. || Another important aspect is to make sure mycologists, artists, and society are all on the same page.",
         "initiatives fostering and supporting works able",
         null,
         "deletion",
         "good",
         "major"
        ],
        [
         "4",
         "SALSA_EXAMPLES_001_SALSA_EXAMPLES",
         "Further important aspects of Fungi in Art relate to preservation of artworks from fungal decay and contamination, as well as initiatives fostering and supporting works able to stimulate dialogues between mycologists (fungal researchers), artists, and society (as for example from the 'Massee Art Grant' by the British Mycological Society or works encouraged and supported by the Fungi Foundation).",
         "An important aspect of Fungi in Art is the protection of artwork from fungal damage. || Another important aspect is to make sure mycologists, artists, and society are all on the same page.",
         "Further important aspects",
         "An important aspect",
         "substitution",
         "trivial",
         "trivial"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentUID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Input Text</th>\n",
       "      <th>Output Text</th>\n",
       "      <th>Edit Type</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Significance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SALSA_EXAMPLES_001_SALSA_EXAMPLES</td>\n",
       "      <td>Further important aspects of Fungi in Art rela...</td>\n",
       "      <td>An important aspect of Fungi in Art is the pro...</td>\n",
       "      <td>(as for example from the 'Massee Art Grant' by...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deletion</td>\n",
       "      <td>good</td>\n",
       "      <td>major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SALSA_EXAMPLES_001_SALSA_EXAMPLES</td>\n",
       "      <td>Further important aspects of Fungi in Art rela...</td>\n",
       "      <td>An important aspect of Fungi in Art is the pro...</td>\n",
       "      <td>(fungal researchers),</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deletion</td>\n",
       "      <td>bad</td>\n",
       "      <td>minor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SALSA_EXAMPLES_001_SALSA_EXAMPLES</td>\n",
       "      <td>Further important aspects of Fungi in Art rela...</td>\n",
       "      <td>An important aspect of Fungi in Art is the pro...</td>\n",
       "      <td>and contamination,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deletion</td>\n",
       "      <td>good</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SALSA_EXAMPLES_001_SALSA_EXAMPLES</td>\n",
       "      <td>Further important aspects of Fungi in Art rela...</td>\n",
       "      <td>An important aspect of Fungi in Art is the pro...</td>\n",
       "      <td>initiatives fostering and supporting works able</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deletion</td>\n",
       "      <td>good</td>\n",
       "      <td>major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SALSA_EXAMPLES_001_SALSA_EXAMPLES</td>\n",
       "      <td>Further important aspects of Fungi in Art rela...</td>\n",
       "      <td>An important aspect of Fungi in Art is the pro...</td>\n",
       "      <td>Further important aspects</td>\n",
       "      <td>An important aspect</td>\n",
       "      <td>substitution</td>\n",
       "      <td>trivial</td>\n",
       "      <td>trivial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             SentUID  \\\n",
       "0  SALSA_EXAMPLES_001_SALSA_EXAMPLES   \n",
       "1  SALSA_EXAMPLES_001_SALSA_EXAMPLES   \n",
       "2  SALSA_EXAMPLES_001_SALSA_EXAMPLES   \n",
       "3  SALSA_EXAMPLES_001_SALSA_EXAMPLES   \n",
       "4  SALSA_EXAMPLES_001_SALSA_EXAMPLES   \n",
       "\n",
       "                                              Source  \\\n",
       "0  Further important aspects of Fungi in Art rela...   \n",
       "1  Further important aspects of Fungi in Art rela...   \n",
       "2  Further important aspects of Fungi in Art rela...   \n",
       "3  Further important aspects of Fungi in Art rela...   \n",
       "4  Further important aspects of Fungi in Art rela...   \n",
       "\n",
       "                                              Target  \\\n",
       "0  An important aspect of Fungi in Art is the pro...   \n",
       "1  An important aspect of Fungi in Art is the pro...   \n",
       "2  An important aspect of Fungi in Art is the pro...   \n",
       "3  An important aspect of Fungi in Art is the pro...   \n",
       "4  An important aspect of Fungi in Art is the pro...   \n",
       "\n",
       "                                          Input Text          Output Text  \\\n",
       "0  (as for example from the 'Massee Art Grant' by...                  NaN   \n",
       "1                              (fungal researchers),                  NaN   \n",
       "2                                 and contamination,                  NaN   \n",
       "3    initiatives fostering and supporting works able                  NaN   \n",
       "4                          Further important aspects  An important aspect   \n",
       "\n",
       "      Edit Type  Quality Significance  \n",
       "0      deletion     good        major  \n",
       "1      deletion      bad        minor  \n",
       "2      deletion     good       medium  \n",
       "3      deletion     good        major  \n",
       "4  substitution  trivial      trivial  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significance_map = {\n",
    "    0: \"trivial\",\n",
    "    1: \"minor\",\n",
    "    2: \"medium\",\n",
    "    3: \"major\"\n",
    "}\n",
    "\n",
    "# load df_edits from official SALSA EXAMPLES\n",
    "df_edits = pd.read_csv(\"../data/salsa_annotations/df_edits_SALSA_ExampleData.csv\")\n",
    "# keep only cols: Source, Target, Edit Classification, Significance\n",
    "#display(df_edits.head())\n",
    "\n",
    "# filter out WikIDE (for now):\n",
    "df_edits = df_edits[df_edits[\"Dataset\"] != \"wikiDE\"]\n",
    "# and DisSim\n",
    "df_edits = df_edits[df_edits[\"System\"] != \"DisSim\"]\n",
    "\n",
    "df_edits['SentUID'] = df_edits['Sentence ID'].astype(str) + \"_\" + df_edits['Dataset'].astype(str)\n",
    "\n",
    "\n",
    "df_edits = df_edits[[\n",
    "    \"SentUID\",\n",
    "    \"Source\",\n",
    "    \"Target\",    \n",
    "    \"Input Text\",\n",
    "    \"Output Text\",\n",
    "    #\"Edit Classification\", \n",
    "   \"Edit Type\",  \n",
    "    \"Quality\",\n",
    "     \"Significance\"\n",
    "    ]]\n",
    "\n",
    "# filter out Edit Classifications with \"ERROR\" in it\n",
    "df_edits = df_edits[~df_edits[\"Edit Type\"].str.contains(\"ERROR\")]\n",
    "\n",
    "# turn significance from 0,1,2,3 to \"trivial\", \"minor\", \"medium\", \"major\"\n",
    "df_edits[\"Significance\"] = df_edits[\"Significance\"].map(significance_map)\n",
    "\n",
    "quality_map = {\n",
    "    \"No Error\": \"good\",\n",
    "    \"Error\": \"bad\",\n",
    "    \"Trivial\": \"trivial\"\n",
    "}\n",
    "\n",
    "# turn Edit Classification to \"good\", \"bad\", \"trivial\" based on Quality Column (No Error, Error, Trivial)\n",
    "df_edits[\"Quality\"] = df_edits[\"Quality\"].map(quality_map)\n",
    "\n",
    "df_edits_fewShotSemiComplex = df_edits.copy()\n",
    "\n",
    "df_edits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System prompt: You are a helpful assistant and expert in text simplification annotations that can identify the changes between two sentences and annotate them using the specified framework.\n",
      "\n",
      "Salsa prompt: You are an expert text simplification analyst using the following framework for a research project. \n",
      "Your task is to analyze the differences between an original sentence and its simplified version. Utmost careful work is paramount here.\n",
      "\n",
      "You are first given some information on the Framework to be used for Text Simplification Annotations:\n",
      "<Framework_Information>\n",
      "The following framework is a comprehensive method for evaluating text simplifications. \n",
      "It provides a structured approach to annotating and analyzing changes made between an original text and its simplified version.\n",
      "\n",
      "The framework recognizes 6 primary types of edits:\n",
      "Deletion, Insertion, Substitution, Split, Reordering, and Structural Changes.\n",
      "\n",
      "- Deletion:\n",
      "       - Good Deletion: Did it remove INSIGNIFICANT information (thus improving the sentence)? Example: \"Like so many hyped books before it, The Midnight Library excited me and gave me pause.\" → \"The Midnight Library excited me and gave me pause.\"\n",
      "       - Trivial Deletion: Was it a trivial deletion?\n",
      "       - Bad Deletion: Did it remove SIGNIFICANT information (deleting necessary and relevant content to the sentence's central meaning)? Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many chemicals are increasing in abundance in the lower troposphere.\" (Removing \"volatile organic\")\n",
      "   - Insertion:\n",
      "        - Good Insertions: Adds meaningful, relevant, and correct information. Example: \"Many volatile organic chemicals are increasing...\" → \"Many volatile organic chemicals, which harm our environment, are increasing...\"\n",
      "        - Trivial Insertion: Adds minor modifications that don't significantly affect meaning or complexity. Example: \"How big is the family you cook for?\" → \"How big is the family THAT you cook for?\"\n",
      "        - Bad Insertions:\n",
      "          - Adds information that simply repeats knowledge already contained in the sentence. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals, which are chemicals, are increasing in abundance in the lower troposphere.\"\n",
      "          - Or adds information unrelated to the main idea of the sentence. Example: \"Many volatile organic chemicals are increasing...\" → \"Many volatile organic chemicals, unlike low vapor pressure chemicals, are increasing...\"\n",
      "          - Or adds information that contradicts the original sentence. Example: \"Many volatile organic chemicals are increasing...\" → \"Many volatile organic chemicals, which are decreasing in our troposphere, are increasing...\"\n",
      "          - Or introduces externally verifiable incorrect information. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals are increasing in abundance in the lower troposphere when they decide to.\"\n",
      "\n",
      "   - Substitution:\n",
      "        - Good Substitution: Swaps complex words with equivalent, simpler alternatives, while retaining the same meaning. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals are being seen more in the lower troposphere.\"\n",
      "        - Trivial Substitution:\n",
      "        - Bad Substitution: Deleting significant information by swapping words, or replacing information with (wrong) new information. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals are decreasing in abundance in the lower troposphere.\"\n",
      "\n",
      "   - Split (subdiving a sentence into smaller sentencens).\n",
      "        - Bad Split: Split at an inappropriate location or interrupted the flow of idea. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals are increasing. They are increasing in abundance in the lower troposphere.\"\n",
      "        - Neutral Split: Divides the sentence without significantly affecting readability or meaning\n",
      "        - Good Split: Improves clarity by separating independent pieces of information into distinct sentences. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals are increasing. They are found in abundance in the lower troposphere.\"\n",
      "        Special hint about Split: Only select the \"||\" divider token and, if any, the replaced or changed words from the input sentence - do NOT select the entire new split sentence.\n",
      "\n",
      "   - Reordering:\n",
      "        - Word-level Reorder: Reorganizes modifiers within a phrase\n",
      "            - Bad: Presented a new word order with less clarity within a clause\n",
      "            - Neutral: Reorders words without significantly affecting clarity or meaning\n",
      "            - Good: Presents a new word order that improves clarity within a clause. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many organic volatile chemicals are increasing in abundance in the lower troposphere.\"\n",
      "        - Component-level Reorder: Moves clauses or content across a sentence\n",
      "            - Bad: Presents a new clausal order that reduces clarity or disrupts the logical flow of ideas\n",
      "            - Neutral: Reorders components without significantly affecting clarity or meaning\n",
      "            - Good: Presents a new clausal order that improves clarity or the logical flow of ideas. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"In the lower troposphere, many volatile organic chemicals are increasing in abundance.\"\n",
      "\n",
      "   - Structural: \n",
      "        - All of the following are considered structural changes, and each can be considered either a \"good structure\", \"trivial structure\", or \"bad structure\" change:\n",
      "          - Voice Change: Changes between active and passive voice. Example: \"Elevation is not primarily considered by the system.\" → \"The system does not primarily consider elevation.\"\n",
      "          - Part-of-Speech Change: Modifies words' derivation or inflection. Example: \"The ability to capture nature scenes has been improving...\" → \"The ability to capture nature scenes has seen improvement...\" Additional example: \"The protesters turned violent when...\" → \"The violent protesters...\"\n",
      "          - Tense Change: Modifies verb modality or tense. \"The governor told reporters he had overseen a productive conversation.\" → \"The governor oversaw a productive conversation.\"\n",
      "          - Grammatical Number Change: Changes between singular and plural or generic and specific. Example: \"Victor had scored that goal against the US in 2011, and another in 2012.\" → \"Victor had scored those goals in 2011 and 2012.\"\n",
      "          - Clausal Change: Modifies predicate structure. Example: \"Donaldson attempted to speak clearly and he was successful.\" → \"Donaldson attempted to speak clearly and successfully.\" Additional example: \"Although it was raining outside, Jobs continued work in his garage.\" → \"Outside it was raining and Jobs continued work in his garage.\"\n",
      "\n",
      "For each edit, we rate its quality: \n",
      " - either good (did it improve the sentence without deleting significant information) or \n",
      " - bad (deleted significant information while simplifying, or had a negative effect on the sentence simplicity), or\n",
      " - trivial (if no significant effects).\n",
      "\n",
      "For each edit, we rate its significance as a level out of the following three:\n",
      "   significance levels for negative changes:\n",
      "    - 1: minor (changes, but sentence retains central meaning)\n",
      "    - 2: medium (significant changes, but sentence retains central meaning)\n",
      "    - 3: major (significant changes, changing or removing the sentence's central meaning or information)\n",
      "    significance levels for positive changes:\n",
      "    - 1: minor (slight improvement in readibility/understandability)\n",
      "    - 2: medium (some improvement in improving a sentence's understandability)\n",
      "    - 3: major (significant changes in improving a sentence's understandability, while retaining it's core meaning)\n",
      "\n",
      "</Framework_Information>\n",
      "\n",
      "Now with this knowledge, follow these steps carefully:\n",
      "\n",
      "<instructions>\n",
      "1. Input: You will be presented with two sentences:\n",
      "<original_sentence>\n",
      "{{ORIGINAL_SENTENCE}}\n",
      "</original_sentence>\n",
      "\n",
      "<simplified_sentence>\n",
      "{{SIMPLIFIED_SENTENCE}}\n",
      "</simplified_sentence>\n",
      "\n",
      "2. Identify Changes:\n",
      "List all changes you observe between the original and simplified sentences. \n",
      "For each change, specify the affected words as a string (e.g. \"The quick brown\").\n",
      "List them all in a <identified_changes> section.\n",
      "Important: Try to avoid overlapping edits, meaning a given word should ideally only be present in one identified edit and edits should not overlap.\n",
      "And try to keep an edit to its smallest possible size (e.g., split up bigger edits into their components when sensible instead of marking half of a sentence as one big edit).\n",
      "Very important: Every single edit MUST have associated word(s) or spans of words, even splits or structure changes. Never indicate an edit operation that has not at least either an input or output text part associated with it.\n",
      "\n",
      "3. Categorize Changes:\n",
      "For each change you identified, categorize its type according to the framework. \n",
      "Determine if it's a Deletion, Insertion, Substitution, Reordering, Split, or Structural change. \n",
      "List them all in a <categorized_changes> section.\n",
      "\n",
      "4. Analyze quality and rate significance:\n",
      "For each categorized change, analyze its quality and significance.\n",
      "First, determine if it's good, neutral, or bad according to the framework criteria and rate the significance of each change on a scale of minor, medium, major. Justify each rating based on the framework guidelines.\n",
      "List them all in a <rating_changes> section.\n",
      "\n",
      "5. Detect Errors:\n",
      "Examine the simplified sentence for any potential errors, such as coreference issues or grammar and fluency problems. \n",
      "List any errors you find in a <errors> section.\n",
      "\n",
      "6. Generate OUTPUT CSV Structure:\n",
      "Based on your analysis and all the information you created, create a CSV structure for the analyzed sentence pair that follows the format of the examples supplied below.\n",
      "Create one row for each edit.\n",
      "\n",
      "Between <OUTPUT> and </OUTPUT>, output only the CSV lines. Do not include headings, bullet points, or explanatory text. \n",
      "The first line inside <OUTPUT>...</OUTPUT> must be the header\n",
      "\n",
      "Example output section:\n",
      "<OUTPUT>\n",
      "input_segment,output_segment,edit_type,quality,significance\n",
      "\"Apfel\",\"Birne\",substitution,good,minor\n",
      "...\n",
      "</OUTPUT>\n",
      "\n",
      "\n",
      "7. Review and Refine:\n",
      "Review the edits you've identified and properly formatted. Ensure all changes are accurately represented and all required fields are present. \n",
      "Try avoiding overlapping edits.\n",
      "Use the examples below and the framework guidelines as help. Make any necessary adjustments.\n",
      "</instructions>\n",
      "\n",
      "Example output formats:\n",
      "<examples>\n",
      "<TODO INSERT EXAMPLE>\n",
      "</examples>\n",
      "\n",
      "Remember to be thorough in your analysis and think step by step. Verify your output format at the end, to validate its properly formatted or change it if necessary.\n"
     ]
    }
   ],
   "source": [
    "# read in prompt files (txt)\n",
    "system_prompt_import = open(\"prompts_LLM_annotations/system_prompt_annotations.txt\", \"r\").read()\n",
    "print(f\"System prompt: {system_prompt_import}\")\n",
    "print()\n",
    "\n",
    "SemiComplex_Prompt_CoT_import = open(\"prompts_LLM_annotations/SemiComplex_Prompt_CoT.txt\", \"r\").read()\n",
    "print(f\"Salsa prompt: {SemiComplex_Prompt_CoT_import}\")\n",
    "\n",
    "def prompt_assembly_semicomplex(sentence1, sentence2, n_fewshot_samples=3, prompt=SemiComplex_Prompt_CoT_import):\n",
    "    if n_fewshot_samples == 0:\n",
    "        try:\n",
    "            prompt_combined = prompt.split(\"<examples>\")[0]\n",
    "            prompt_combined += prompt.split(\"</examples>\")[1]\n",
    "            prompt_combined += prompt_insert_sentence_pair_semicomplex(sentence1, sentence2)\n",
    "        except:\n",
    "            prompt_combined = prompt[:] # deep copy prompt:\n",
    "            prompt_combined += prompt_insert_sentence_pair_semicomplex(sentence1, sentence2)\n",
    "\n",
    "    else:\n",
    "        prompt_combined = prompt.split(\"<examples>\")[0]\n",
    "        prompt_combined += \"\\n\\n\"\n",
    "        prompt_combined += \"<examples>\"\n",
    "        prompt_combined += \"\\n\\n\"\n",
    "        prompt_combined += str(generate_n_random_examples_dfEdits(\n",
    "            df_edits_fewShotSemiComplex, \n",
    "            n=n_fewshot_samples)) # samples of edits per sentence pair\n",
    "        prompt_combined += \"</examples>\"\n",
    "        prompt_combined += \"\\n\\n\"\n",
    "        prompt_combined += prompt.split(\"</examples>\")[1]\n",
    "        prompt_combined += prompt_insert_sentence_pair_semicomplex(sentence1, sentence2)\n",
    "    \n",
    "    return prompt_combined\n",
    "\n",
    "def prompt_insert_sentence_pair_semicomplex(sentence1, sentence2):\n",
    "    return f\"\"\"\n",
    "\n",
    "Here is the sentence pair you need to annotate:\n",
    "<original_sentence>{sentence1}</original_sentence>\n",
    "<simplified_sentence>{sentence2}</simplified_sentence>\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_n_random_examples_dfEdits(df_in, n,\n",
    "                                     header_names = ['SentUID', \"source\", \"target\", \"input_segment\", \n",
    "                                                   \"output_segment\", \"edit_type\", \"quality\", \"significance\"]):\n",
    "    df = df_in.copy()\n",
    "    df.columns = header_names\n",
    "    grouped = df.groupby('SentUID')\n",
    "    formatted_examples = \"\"\n",
    "    sentences_used = 0\n",
    "    \n",
    "    csv_header = \"input_segment,output_segment,edit_type,quality,significance\"\n",
    "    edit_cols = ['input_segment', 'output_segment', 'edit_type', 'quality', 'significance']\n",
    "    \n",
    "    while sentences_used < n:\n",
    "        sent_id = np.random.choice(df['SentUID'].unique())\n",
    "        sent_group = grouped.get_group(sent_id)\n",
    "        \n",
    "        # Sentence pair formatting\n",
    "        formatted_examples += f\"<complex_sentence>\\n{sent_group['source'].iloc[0]}\\n</complex_sentence>\\n\\n\"\n",
    "        formatted_examples += f\"<simplified_sentence>\\n{sent_group['target'].iloc[0]}\\n</simplified_sentence>\\n\\n\"\n",
    "        \n",
    "        # CSV header\n",
    "        formatted_examples += f\"{csv_header}\\n\"\n",
    "        # Edit rows in CSV format\n",
    "        for _, edit in sent_group[edit_cols].iterrows():\n",
    "            row = ','.join(str(edit[col]) for col in edit_cols)\n",
    "            formatted_examples += f\"{row}\\n\"\n",
    "            \n",
    "        formatted_examples += \"\\n---\\n\\n\"\n",
    "        sentences_used += 1\n",
    "    \n",
    "    return formatted_examples\n",
    "\n",
    "#print(generate_n_random_examples_dfEdits(df_edits_fewShotSemiComplex, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "def extract_all_output_blocks(response_text):\n",
    "    \"\"\"\n",
    "    Finds *all* text blocks enclosed by <OUTPUT>...</OUTPUT>.\n",
    "    May skip optional ``` delimiters (csv, plaintext, xml, etc.).\n",
    "    Returns a list of extracted strings, one per block.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"<OUTPUT>\"\n",
    "        r\"(?:```(?:csv|plaintext|xml)?\\s*)?\"  # Optional code fence marker\n",
    "        r\"(.*?)\"                              # Capture block content\n",
    "        r\"(?:```)?\"\n",
    "        r\"</OUTPUT>\",\n",
    "        re.DOTALL | re.IGNORECASE\n",
    "    )\n",
    "    matches = pattern.findall(response_text)\n",
    "    # Strip each match to remove leading/trailing whitespace\n",
    "    return [m.strip() for m in matches]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_all_csv_blocks(response_text):\n",
    "    \"\"\"\n",
    "    Extracts all <OUTPUT> blocks from the response_text, parses each into\n",
    "    a DataFrame, and concatenates them into a single DataFrame.\n",
    "    Returns an empty DataFrame if none is parsed successfully.\n",
    "    \"\"\"\n",
    "    blocks = extract_all_output_blocks(response_text)\n",
    "    dfs = []\n",
    "    for block in blocks:\n",
    "        df_block = parse_single_csv_block(block)\n",
    "        if not df_block.empty:\n",
    "            dfs.append(df_block)\n",
    "\n",
    "    if dfs:\n",
    "        return pd.concat(dfs, ignore_index=True)\n",
    "    else:\n",
    "        # Return an empty DataFrame with the correct columns if no valid CSV found\n",
    "        return pd.DataFrame(\n",
    "            columns=[\"input_segment\",\"output_segment\",\"edit_type\",\"quality\",\"significance\"]\n",
    "        )\n",
    "\n",
    "\n",
    "def process_api_response(response):\n",
    "    \"\"\"\n",
    "    For each API response, grab all <OUTPUT> CSV blocks, parse them,\n",
    "    and return one combined DataFrame.\n",
    "    \"\"\"\n",
    "    response_text = response.choices[0].message.content\n",
    "    df_combined = parse_all_csv_blocks(response_text)\n",
    "    return df_combined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Step Pipeline\n",
    "### More Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are part of a text simplification research project.\\nPlease validate the extracted CSV/output content that is provided below and convert it\\nto the specified JSON data model. Additionally, verify the correct handling of split edits as explained below.\\n\\nJSON data model:\\n{\\n     \"source\": \"<Original complex sentence>\",\\n     \"target\": \"<Simplified sentence>\",\\n     \"edits\": [\\n     {\\n     \"category\": \"<Edit type: Deletion, Insertion, Substitution, Reordering, Split, Structural>\",\\n     \"input_text\": \"<Affected words (if any) in the original sentence>\",\\n     \"output_text\": \"<Affected words (if any) in the simplified sentence>\",\\n     \"quality\": \"<Quality rating: good, bad, or trivial>\",\\n     \"significance\": <Significance level: 0 (trivial), 1 (minor), 2 (medium), 3 (major)>\\n     }\\n     ]\\n}\\n\\nImportant Note About input_text and output_text:\\nIf the edit affects a continuous span of words, store them as a single string inside the array.\\nExample: [\"The quick brown fox\"], NOT [\"The\", \"quick\", \"brown\", \"fox\"].\\nIf multiple non-sequential segments are affected, store them as separate strings inside the array.\\nExample: [\"The quick\", \"fox\"].\\nVery important: Every single edit MUST have associated word(s) or spans of words, even splits or structure changes. Never indicate an edit operation that has not at least either an input or output text part associated with it.\\nA note about splits: If the input annotations have marked entire spans of a sentence as affected by a split, you have permission to change it.\\nExample: \\n- Wrong annotation: input_text: [\"jumped over the bridge and later ran across the\"] output_text: [\"jumped over the bridge. || He later ran across the\"]\\n- Correct annotation: input_text: [\"and\"] output_text: [\"|| He\"]\\n\\nExample Final Output:\\n{\\n  \"source\": \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\",\\n  \"target\": \"Many organic chemicals, which harm the environment, are increasing in the troposphere.\",\\n  \"edits\": [\\n    {\\n      \"category\": \"Deletion\",\\n      \"id\": 1,\\n      \"input_text\": [\"volatile\"],\\n      \"output_text\": [],\\n      \"quality\": \"good\",\\n      \"significance\": 2\\n    },\\n    {\\n      \"category\": \"Insertion\",\\n      \"id\": 2,\\n      \"input_text\": [],\\n      \"output_text\": [\"which harm the environment\"],\\n      \"quality\": \"good\",\\n      \"significance\": 2\\n    },\\n    {\\n      \"category\": \"Substitution\",\\n      \"id\": 3,\\n      \"input_text\": [\"in abundance in the lower troposphere\"],\\n      \"output_text\": [\"in the troposphere\"],\\n      \"quality\": \"bad\",\\n      \"significance\": 3\\n    }\\n  ]\\n}\\n\\nActual data to convert:\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_prompt_import = open(\"prompts_LLM_annotations/SemiComplex_Prompt_ValidationStep.txt\", \"r\").read()\n",
    "validation_prompt_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define allowed categories\n",
    "EditCategory = Literal[\n",
    "    'deletion',\n",
    "    'substitution', \n",
    "    'insertion',\n",
    "    'reorder',\n",
    "    'structure',\n",
    "    'split'\n",
    "]\n",
    "\n",
    "# Define quality types\n",
    "EditQuality = Literal['good', 'bad', 'trivial']\n",
    "\n",
    "# Define significance levels\n",
    "SignificanceLevel = Literal[0, 1, 2, 3]\n",
    "\n",
    "class EditSemiComplex(BaseModel):\n",
    "    category: EditCategory\n",
    "    input_text: List[str] = Field(description=\"The words in the complex (input) sentence affected by the edit\")\n",
    "    output_text: List[str] = Field(description=\"The words in the simplified (output) sentence affected by the edit\")\n",
    "    quality: EditQuality = Field(description=\"Quality of edit: good, bad, or trivial\")\n",
    "    significance: SignificanceLevel = Field(description=\"Significance level: 0 for trivial, 1-3 for good/bad depending on severity (minor: 1, medium: 2, major: 3)\")\n",
    "\n",
    "class DataModelSemiComplex(BaseModel):\n",
    "    source: str = Field(description=\"The original complex sentence\")\n",
    "    target: str = Field(description=\"The simplified sentence\") \n",
    "    edits: List[EditSemiComplex] = Field(description=\"List of simplification edits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import logging\n",
    "import pandas as pd\n",
    "import openai\n",
    "from typing import Optional\n",
    "from io import StringIO\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_all_output_blocks(response_text):\n",
    "    \"\"\"\n",
    "    Extracts all <OUTPUT>...</OUTPUT> blocks from the response_text.\n",
    "    Handles optional code fences like ```csv, ```plaintext, etc.\n",
    "    Falls back to text after the first \"OUTPUT\" occurrence if no blocks are found.\n",
    "    If that also fails, returns the entire response text.\n",
    "\n",
    "    Parameters:\n",
    "    - response_text (str): The full text response from the API.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: A list of strings containing the extracted content.\n",
    "    \"\"\"\n",
    "    pattern = re.compile(\n",
    "        r\"<OUTPUT>\\s*(?:```(?:csv|plaintext|json|xml)?\\s*)?(.*?)\\s*(?:```)?\\s*</OUTPUT>\",\n",
    "        re.DOTALL | re.IGNORECASE\n",
    "    )\n",
    "    matches = pattern.findall(response_text)\n",
    "\n",
    "    if matches:\n",
    "        return [match.strip() for match in matches]\n",
    "\n",
    "    # Fallback: Try to extract everything after the first \"OUTPUT\"\n",
    "    output_index = response_text.lower().find(\"output\")\n",
    "    if output_index != -1:\n",
    "        return [response_text[output_index + len(\"output\"):].strip()]\n",
    "\n",
    "    # Final fallback: return the entire text\n",
    "    return [response_text.strip()]\n",
    "\n",
    "\n",
    "\n",
    "def isolate_csv_content(output_block):\n",
    "    \"\"\"\n",
    "    Isolates the CSV or output content from a single <OUTPUT> block.\n",
    "    \n",
    "    Parameters:\n",
    "    - output_block (str): The content within a single <OUTPUT>...</OUTPUT> block.\n",
    "    \n",
    "    Returns:\n",
    "    - str: The isolated CSV or output content.\n",
    "    \"\"\"\n",
    "    return output_block\n",
    "\n",
    "def process_api_response(response):\n",
    "    \"\"\"\n",
    "    Processes the API response to extract CSV/output annotations.\n",
    "\n",
    "    Parameters:\n",
    "    - response: The API response object.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: A list of extracted CSV/output content strings.\n",
    "    \"\"\"\n",
    "    response_text = response.choices[0].message.content\n",
    "    output_blocks = extract_all_output_blocks(response_text)\n",
    "    \n",
    "    if not output_blocks:\n",
    "        logging.warning(\"No <OUTPUT> blocks found in the API response.\")\n",
    "    \n",
    "    return output_blocks\n",
    "\n",
    "\n",
    "\n",
    "def generate_semicomplex_annotations_for_csv(\n",
    "    csv_file_path: str,\n",
    "    output_json_path: str,\n",
    "    output_csv_path: str,\n",
    "    num_samples: Optional[int] = None,\n",
    "    seed: int = 42,\n",
    "    prompt: str = SemiComplex_Prompt_CoT_import,\n",
    "    validation_prompt: str = validation_prompt_import,\n",
    "    datamodel_validationstep = DataModelSemiComplex,\n",
    "    n_fewshot_samples: int = 6,\n",
    "    modelname: str = \"gpt\"\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Generate semicomplex annotations, validate them, and output a structured JSON file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        print(f\"Successfully read CSV file: {csv_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        return\n",
    "\n",
    "    required_columns = {\"complex_sentence\", \"simplified_sentence\"}\n",
    "    if not required_columns.issubset(df.columns):\n",
    "        print(f\"CSV must contain the columns: {required_columns}\")\n",
    "        # rename columns if needed\n",
    "        df.rename(columns={\"Original\": \"complex_sentence\", \"Simplified\": \"simplified_sentence\"}, inplace=True)\n",
    "        df.rename(columns={\"original_sentence\": \"complex_sentence\", \"simplified_sentence\": \"simplified_sentence\"}, inplace=True)\n",
    "\n",
    "    if num_samples and num_samples < len(df):\n",
    "        df = df.sample(n=num_samples, random_state=seed)\n",
    "        print(f\"Sampled {num_samples} rows.\")\n",
    "\n",
    "    annotations_list = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        original_sentence = row[\"complex_sentence\"]\n",
    "        simplified_sentence = row[\"simplified_sentence\"]\n",
    "\n",
    "        print(f\"\\n### Processing row {index + 1}:\")\n",
    "        print(f\"Original: {original_sentence}\")\n",
    "        print(f\"Simplified: {simplified_sentence}\")\n",
    "\n",
    "        prompt_out = prompt_assembly_semicomplex(original_sentence, simplified_sentence, n_fewshot_samples=n_fewshot_samples, prompt=prompt)\n",
    "        print(\"\\n--- Generated Prompt ---\\n\", prompt_out)\n",
    "\n",
    "        try:\n",
    "            response = openai_client.chat.completions.create(\n",
    "                model=model_gpt,\n",
    "                messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant in a text simplification research project.\"},\n",
    "                          {\"role\": \"user\", \"content\": prompt_out}],\n",
    "            )\n",
    "            extracted_contents = process_api_response(response)\n",
    "            print(\"\\n--- Extracted Content ---\\n\", extracted_contents)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"API request failed for row {index + 1}: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            validation_response = openai_client.chat.completions.create(\n",
    "                model=model_gpt,\n",
    "                messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant in a text simplification research project.\"},\n",
    "                            {\"role\": \"user\", \"content\": validation_prompt + \n",
    "                            f\"\\n\\nOriginal Sentence: {original_sentence}\\n\\nSimplified Sentence: {simplified_sentence}\\n\\n\" +\n",
    "                            f\"--- Extracted Annotations to validate and transform: ---\\n\\n\" +\n",
    "                            f\"\\n\\n\".join(extracted_contents)}],\n",
    "                response_format={\n",
    "                    \"type\": \"json_schema\",\n",
    "                    \"json_schema\": {\"name\": \"name1\", \"schema\": datamodel_validationstep.model_json_schema()}\n",
    "                }\n",
    "            )\n",
    "            validated_annotations = json.loads(validation_response.choices[0].message.content)\n",
    "\n",
    "            print(\"\\n--- Validated Annotations ---\\n\", json.dumps(validated_annotations, indent=4, ensure_ascii=False))\n",
    "\n",
    "            annotation_entry = {\n",
    "                \"source\": original_sentence,\n",
    "                \"target\": simplified_sentence,\n",
    "                \"metadata\": {\"annotator\": \"annotator_0\", \"system\": \"UNDEFINED\"}, \n",
    "                \"edits\": validated_annotations.get(\"edits\", []),\n",
    "                \"_thresh_id\": index + 1\n",
    "            }\n",
    "            annotations_list.append(annotation_entry)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Validation request failed for row {index + 1}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Save aggregated results as JSON\n",
    "    with open(output_json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump(annotations_list, json_file, ensure_ascii=False, indent=4)\n",
    "    print(f\"\\n Aggregated annotations saved to {output_json_path}\")\n",
    "\n",
    "    # Convert JSON to CSV and save\n",
    "    output_df = pd.DataFrame(annotations_list)\n",
    "    output_df.to_csv(output_csv_path, index=False, encoding=\"utf-8\")\n",
    "    print(f\"\\n Aggregated annotations saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enhanced API calls for multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup API Clients\n",
    "replicateClient = replicate.Client(api_token=replicate_key)\n",
    "\n",
    "clientAnthropic = Anthropic(api_key=anthropic_key)\n",
    "\n",
    "LMstudio_client = OpenAI(\n",
    "    base_url=\"http://localhost:1234/v1\",\n",
    "    api_key=\"lm-studio\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_generation_api_concurrent(prompt: str, model: str) -> str:\n",
    "    \"\"\"\n",
    "    Calls the correct API using a per-API lock to ensure that only one call is active per API type.\n",
    "    Returns the raw response message as a string.\n",
    "    \"\"\"\n",
    "    api_type = get_api_type(model)\n",
    "\n",
    "    with API_LOCKS[api_type]:\n",
    "        raw_message = \"\"\n",
    "        if api_type == \"replicate\":\n",
    "            print(f\"[{model}] Sending request to Replicate...\")\n",
    "            output = replicateClient.run(model, input={\"prompt\": prompt})\n",
    "            raw_message = \"\".join(output)\n",
    "        elif api_type == \"local\":\n",
    "            print(f\"[{model}] Sending request to Local API...\")\n",
    "            time.sleep(np.random.randint(0, 2))\n",
    "            response = LMstudio_client.chat.completions.create(\n",
    "                    model=\"someString\", \n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a helpful assistant in a text simplification research project.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ])\n",
    "            raw_message = response.choices[0].message.content\n",
    "\n",
    "        elif api_type == \"anthropic\":\n",
    "            print(f\"[{model}] Sending request to Anthropic...\")\n",
    "            time.sleep(np.random.randint(0, 10))\n",
    "            response = clientAnthropic.messages.create(\n",
    "                max_tokens=8096,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                model=model\n",
    "            )\n",
    "            raw_message = response.content[0].text\n",
    "        else:  # Azure OpenAI (GPT)\n",
    "            print(f\"[{model}] Sending request to Azure OpenAI...\")\n",
    "            time.sleep(np.random.randint(0, 10))\n",
    "            response = openai_client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant in a text simplification research project.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "            )\n",
    "            raw_message = response.choices[0].message.content\n",
    "\n",
    "    print(f\"[{model}] Received response.\")\n",
    "    return raw_message\n",
    "\n",
    "def process_model(\n",
    "    model: str,\n",
    "    df: pd.DataFrame,\n",
    "    n_fewshot_samples: int,\n",
    "    prompt: str,\n",
    "    validation_prompt: str,\n",
    "    datamodel_validationstep,\n",
    "    model_gpt: str\n",
    ") -> List[dict]:\n",
    "    \"\"\"\n",
    "    Processes the entire CSV file for a single model.\n",
    "    Iterates sequentially through all rows and returns a list of annotation entries.\n",
    "    \"\"\"\n",
    "    annotations_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        original_sentence = row[\"complex_sentence\"]\n",
    "        simplified_sentence = row[\"simplified_sentence\"]\n",
    "\n",
    "        print(f\"\\n[{model}] Processing row {index + 1}:\")\n",
    "        print(\"Original:\", original_sentence)\n",
    "        print(\"Simplified:\", simplified_sentence)\n",
    "\n",
    "        # Assemble the prompt (assume prompt_assembly_semicomplex is defined elsewhere)\n",
    "        prompt_out = prompt_assembly_semicomplex(\n",
    "            original_sentence, simplified_sentence,\n",
    "            n_fewshot_samples=n_fewshot_samples,\n",
    "            prompt=prompt\n",
    "        )\n",
    "        print(f\"[{model}] Generated Prompt:\\n{prompt_out}\")\n",
    "\n",
    "        # --- Step 1: Generation API call ---\n",
    "        try:\n",
    "            raw_response = call_generation_api_concurrent(prompt_out, model)\n",
    "            print(f\"[{model}] Raw response: {raw_response}\")\n",
    "            extracted_contents = extract_all_output_blocks(raw_response)\n",
    "            print(f\"[{model}] Extracted Content:\\n{extracted_contents}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[{model}] API request failed for row {index + 1}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # --- Step 2: Validation via OpenAI ---\n",
    "        try:\n",
    "            validation_input = (\n",
    "                validation_prompt +\n",
    "                f\"\\n\\nOriginal Sentence: {original_sentence}\\n\\nSimplified Sentence: {simplified_sentence}\\n\\n\" +\n",
    "                \"--- Extracted Annotations to validate and transform: ---\\n\\n\" +\n",
    "                \"\\n\\n\".join(extracted_contents)\n",
    "            )\n",
    "            validation_response = openai_client.chat.completions.create(\n",
    "                model=model_gpt,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant in a text simplification research project.\"},\n",
    "                    {\"role\": \"user\", \"content\": validation_input}\n",
    "                ],\n",
    "                response_format={\n",
    "                    \"type\": \"json_schema\",\n",
    "                    \"json_schema\": {\"name\": \"name1\", \"schema\": datamodel_validationstep.model_json_schema()}\n",
    "                }\n",
    "            )\n",
    "            validated_annotations = json.loads(validation_response.choices[0].message.content)\n",
    "            print(f\"[{model}] Validated Annotations:\\n\", json.dumps(validated_annotations, indent=4, ensure_ascii=False))\n",
    "        except Exception as e:\n",
    "            print(f\"[{model}] Validation failed for row {index + 1}: {e}\")\n",
    "            continue\n",
    "\n",
    "        annotation_entry = {\n",
    "            \"source\": original_sentence,\n",
    "            \"target\": simplified_sentence,\n",
    "            \"metadata\": {\"annotator\": model, \"system\": get_api_type(model)},\n",
    "            \"edits\": validated_annotations.get(\"edits\", []),\n",
    "            \"_thresh_id\": index + 1\n",
    "        }\n",
    "        annotations_list.append(annotation_entry)\n",
    "    return annotations_list\n",
    "\n",
    "def generate_semicomplex_annotations_for_csv_multi_model(\n",
    "    csv_file_path: str,\n",
    "    output_dir: str,\n",
    "    models: List[str],\n",
    "    num_samples: Optional[int] = None,\n",
    "    seed: int = 42,\n",
    "    prompt: str = \"YOUR_SEMI_COMPLEX_PROMPT\",\n",
    "    validation_prompt: str = \"YOUR_VALIDATION_PROMPT\",\n",
    "    datamodel_validationstep=None,\n",
    "    n_fewshot_samples: int = 6,\n",
    "    taxName_for_filename: str = 'noTaxName',\n",
    "    ID_filter = None, # allow to filter for specific IDs\n",
    "    model_gpt: str = \"gpt-4\"  # default GPT model for validation\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes a CSV file. For each model, the entire file is processed sequentially,\n",
    "    but the processing for different models happens concurrently.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path, encoding=\"mac_roman\")\n",
    "        print(f\"Successfully read CSV file: {csv_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        return\n",
    "\n",
    "    # Ensure required columns exist or rename them accordingly.\n",
    "    required_columns = {\"complex_sentence\", \"simplified_sentence\"}\n",
    "    if not required_columns.issubset(df.columns):\n",
    "        print(f\"CSV must contain the columns: {required_columns}\")\n",
    "        df.rename(columns={\"Original\": \"complex_sentence\", \"Simplified\": \"simplified_sentence\"}, inplace=True)\n",
    "        df.rename(columns={\"original_sentence\": \"complex_sentence\", \"simplified_sentence\": \"simplified_sentence\"}, inplace=True)\n",
    "\n",
    "    if num_samples and num_samples < len(df):\n",
    "        df = df.sample(n=num_samples, random_state=seed)\n",
    "        print(f\"Sampled {num_samples} rows.\")\n",
    "\n",
    "    if ID_filter:  # filter index of df\n",
    "        # subtract 1 from all IDs to match 0-based index\n",
    "        ID_filter = [x - 1 for x in ID_filter]\n",
    "        df = df[df.index.isin(ID_filter)]\n",
    "        print(f\"Filtered rows with IDs: {ID_filter}\")\n",
    "\n",
    "    annotations_by_model = {}\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    # Create one thread per model.\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=len(models)) as executor:\n",
    "        future_to_model = {\n",
    "            executor.submit(\n",
    "                process_model,\n",
    "                model,\n",
    "                df,\n",
    "                n_fewshot_samples,\n",
    "                prompt,\n",
    "                validation_prompt,\n",
    "                datamodel_validationstep,\n",
    "                model_gpt\n",
    "            ): model for model in models\n",
    "        }\n",
    "        for future in concurrent.futures.as_completed(future_to_model):\n",
    "            model = future_to_model[future]\n",
    "            try:\n",
    "                annotations_list = future.result()\n",
    "                annotations_by_model[model] = annotations_list\n",
    "\n",
    "                # Save JSON output.\n",
    "                model_name_safe = model.replace(\"/\", \"_\")\n",
    "                json_output_path = os.path.join(output_dir, f\"LLM_annotations_{taxName_for_filename}_{model_name_safe}_{current_time}.json\")\n",
    "                with open(json_output_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "                    json.dump(annotations_list, json_file, ensure_ascii=False, indent=4)\n",
    "                print(f\"[{model}] Saved JSON annotations to {json_output_path}\")\n",
    "\n",
    "                # Save CSV output.\n",
    "                output_df = pd.DataFrame(annotations_list)\n",
    "                csv_output_path = os.path.join(output_dir, f\"LLM_annotations_{taxName_for_filename}_{model_name_safe}_{current_time}.csv\")\n",
    "                output_df.to_csv(csv_output_path, index=False, encoding=\"utf-8\")\n",
    "                print(f\"[{model}] Saved CSV annotations to {csv_output_path}\")\n",
    "            except Exception as exc:\n",
    "                print(f\"[{model}] generated an exception: {exc}\")\n",
    "\n",
    "    return annotations_by_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_LOCKS = {\n",
    "    \"azure\": threading.Lock(),\n",
    "    \"anthropic\": threading.Lock(),\n",
    "    \"replicate\": threading.Lock(),\n",
    "    \"local\": threading.Lock()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution - Peer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Execute (commented out after execution)\n",
    "# df_res = generate_semicomplex_annotations_for_csv(\n",
    "#     csv_file_path=\"../data/salsa_peer_annotations/salsa_peer_data_wikiDE_random.csv\",\n",
    "#     output_json_path=\"../data/salsa_annotations/LLM_annotations_output/LLM_annotations_001b.json\",\n",
    "#     output_csv_path=\"../data/salsa_annotations/LLM_annotations_output/LLM_annotations_001b.csv\",\n",
    "#     num_samples=None # None: run on entire set\n",
    "# )\n",
    "# # \n",
    "# df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an expert text simplification analyst using the following framework for a research project. \\nYour task is to analyze the differences between an original sentence and its simplified version. Utmost careful work is paramount here.\\n\\nYou are first given some information on the Framework to be used for Text Simplification Error Annotations:\\n\\n<Framework_Information>\\nThe following framework is a comprehensive method for evaluating errors in LLM-generated text simplifications.\\nIt provides a structured approach to annotating and analyzing erroneous changes made between an original text and its simplified version.\\nThe framework govers both good and bad edit types, but you will later focus on the bad edit types.\\n\\nThe framework recognizes 6 primary types of edits:\\nDeletion, Insertion, Substitution, Split, Reordering, and Structural Changes.\\n\\n- Deletion:\\n       - Good Deletion: Did it remove INSIGNIFICANT information (thus improving the sentence)? Example: \"Like so many hyped books before it, The Midnight Library excited me and gave me pause.\" → \"The Midnight Library excited me and gave me pause.\"\\n       - Trivial Deletion: Was it a trivial deletion?\\n       - Bad Deletion: Did it remove SIGNIFICANT information (deleting necessary and relevant content to the sentence\\'s central meaning)? Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many chemicals are increasing in abundance in the lower troposphere.\" (Removing \"volatile organic\")\\n   - Insertion:\\n        - Good Insertions: Adds meaningful, relevant, and correct information. Example: \"Many volatile organic chemicals are increasing...\" → \"Many volatile organic chemicals, which harm our environment, are increasing...\"\\n        - Trivial Insertion: Adds minor modifications that don\\'t significantly affect meaning or complexity. Example: \"How big is the family you cook for?\" → \"How big is the family THAT you cook for?\"\\n        - Bad Insertions:\\n          - Adds information that simply repeats knowledge already contained in the sentence. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals, which are chemicals, are increasing in abundance in the lower troposphere.\"\\n          - Or adds information unrelated to the main idea of the sentence. Example: \"Many volatile organic chemicals are increasing...\" → \"Many volatile organic chemicals, unlike low vapor pressure chemicals, are increasing...\"\\n          - Or adds information that contradicts the original sentence. Example: \"Many volatile organic chemicals are increasing...\" → \"Many volatile organic chemicals, which are decreasing in our troposphere, are increasing...\"\\n          - Or introduces externally verifiable incorrect information. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals are increasing in abundance in the lower troposphere when they decide to.\"\\n\\n   - Substitution:\\n        - Good Substitution: Swaps complex words with equivalent, simpler alternatives, while retaining the same meaning. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals are being seen more in the lower troposphere.\"\\n        - Trivial Substitution:\\n        - Bad Substitution: Deleting significant information by swapping words, or replacing information with (wrong) new information. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals are decreasing in abundance in the lower troposphere.\"\\n\\n   - Split (subdiving a sentence into smaller sentencens).\\n        - Bad Split: Split at an inappropriate location or interrupted the flow of idea. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals are increasing. They are increasing in abundance in the lower troposphere.\"\\n        - Neutral Split: Divides the sentence without significantly affecting readability or meaning\\n        - Good Split: Improves clarity by separating independent pieces of information into distinct sentences. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals are increasing. They are found in abundance in the lower troposphere.\"\\n        Special hint about Split: Only select the \"||\" divider token and, if any, the replaced or changed words from the input sentence - do NOT select the entire new split sentence.\\n\\n   - Reordering:\\n        - Word-level Reorder: Reorganizes modifiers within a phrase\\n            - Bad: Presented a new word order with less clarity within a clause\\n            - Neutral: Reorders words without significantly affecting clarity or meaning\\n            - Good: Presents a new word order that improves clarity within a clause. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many organic volatile chemicals are increasing in abundance in the lower troposphere.\"\\n        - Component-level Reorder: Moves clauses or content across a sentence\\n            - Bad: Presents a new clausal order that reduces clarity or disrupts the logical flow of ideas\\n            - Neutral: Reorders components without significantly affecting clarity or meaning\\n            - Good: Presents a new clausal order that improves clarity or the logical flow of ideas. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"In the lower troposphere, many volatile organic chemicals are increasing in abundance.\"\\n\\n   - Structural: \\n        - All of the following are considered structural changes, and each can be considered either a \"good structure\", \"trivial structure\", or \"bad structure\" change:\\n          - Voice Change: Changes between active and passive voice. Example: \"Elevation is not primarily considered by the system.\" → \"The system does not primarily consider elevation.\"\\n          - Part-of-Speech Change: Modifies words\\' derivation or inflection. Example: \"The ability to capture nature scenes has been improving...\" → \"The ability to capture nature scenes has seen improvement...\" Additional example: \"The protesters turned violent when...\" → \"The violent protesters...\"\\n          - Tense Change: Modifies verb modality or tense. \"The governor told reporters he had overseen a productive conversation.\" → \"The governor oversaw a productive conversation.\"\\n          - Grammatical Number Change: Changes between singular and plural or generic and specific. Example: \"Victor had scored that goal against the US in 2011, and another in 2012.\" → \"Victor had scored those goals in 2011 and 2012.\"\\n          - Clausal Change: Modifies predicate structure. Example: \"Donaldson attempted to speak clearly and he was successful.\" → \"Donaldson attempted to speak clearly and successfully.\" Additional example: \"Although it was raining outside, Jobs continued work in his garage.\" → \"Outside it was raining and Jobs continued work in his garage.\"\\n\\nFor each edit, we rate its quality: \\n - either good (did it improve the sentence without deleting significant information) or \\n - bad (deleted significant information while simplifying, or had a negative effect on the sentence simplicity), or\\n - trivial (if no significant effects).\\n\\nFor each edit, we rate its significance as a level out of the following three:\\n   significance levels for negative changes:\\n    - 1: minor (changes, but sentence retains central meaning)\\n    - 2: somewhat (significant changes, but sentence retains central meaning)\\n    - 3: a lot (significant changes, changing or removing the sentence\\'s central meaning or information)\\n    significance levels for positive changes:\\n    - 1: minor (slight improvement in readibility/understandability)\\n    - 2: somewhat (some improvement in improving a sentence\\'s understandability)\\n    - 3: a lot (significant changes in improving a sentence\\'s understandability, while retaining it\\'s core meaning)\\n    \\n    (- 0: trivial)\\n\\n</Framework_Information>\\n\\nNow with this knowledge, follow these steps carefully:\\n\\n<instructions>\\n1. Input: You will be presented with two sentences:\\n<original_sentence>\\n{{ORIGINAL_SENTENCE}}\\n</original_sentence>\\n\\n<simplified_sentence>\\n{{SIMPLIFIED_SENTENCE}}\\n</simplified_sentence>\\n\\n2. Identify Changes:\\nList all changes you observe between the original and simplified sentences. \\nFor each change, specify the affected words as a string (e.g. \"The quick brown\").\\nList them all in a <identified_changes> section.\\nImportant: Try to avoid overlapping edits, meaning a given word should ideally only be present in one identified edit and edits should not overlap.\\nAnd try to keep an edit to its smallest possible size (e.g., split up bigger edits into their components when sensible instead of marking half of a sentence as one big edit).\\nVery important: Every single edit MUST have associated word(s) or spans of words, even splits or structure changes. Never indicate an edit operation that has not at least either an input or output text part associated with it.\\n\\n3. Categorize Changes:\\nFor each change:\\nIs it an error or bad edit? If yes, continue. Otherwise, drop this change.\\nIf Error: categorize its type according to the framework. (Ignore good edits in your final output, only bad edits are important in this analysis.)\\nDetermine if it\\'s a Deletion, Insertion, Substitution, Reordering, Split, or Structural change. \\nList them all in a <categorized_changes> section.\\n\\n4. Analyze quality and rate significance:\\nFor each categorized change, analyze its quality and significance.\\nAs the remaining changes should only be errors (bad edits), their quality is automatically \"bad\". Then rate the significance of each change on a scale of minor, somewhat, a lot. Justify each rating based on the framework guidelines.\\nList them all in a <rating_changes> section.\\n\\n5. Detect Errors:\\nExamine the simplified sentence for any potential errors, such as coreference issues or grammar and fluency problems. \\nList any additional errors you find in a <errors> section.\\n\\n6. Generate OUTPUT CSV Structure:\\nBased on your analysis and all the information you created, create a CSV structure for the analyzed sentence pair that follows the format of the examples supplied below.\\nCreate one row for each edit.\\n\\nBetween <OUTPUT> and </OUTPUT>, output only the CSV lines. Do not include headings, bullet points, or explanatory text. \\nThe first line inside <OUTPUT>...</OUTPUT> must be the header\\n\\nExample output section:\\n<OUTPUT>\\ninput_segment,output_segment,edit_type,quality,significance\\n\"brown\",\"dark\",substitution,bad,minor\\n...\\n</OUTPUT>\\n\\n\\n7. Review and Refine:\\nReview the erroneous edits you\\'ve identified and properly formatted. Ensure all relevant changes are accurately represented and all required fields are present. \\nTry avoiding overlapping edits. Keep edits as tight as possible, affecting as few worlds as possible (NOT marking entire clauses when not necessary).\\n\\nUse the examples below and the framework guidelines as help. Make any necessary adjustments.\\n</instructions>\\n\\n<examples>\\n<TODO INSERT EXAMPLE>\\n</examples>\\n\\nRemember to be thorough in your analysis and think step by step. Verify your output format at the end, to validate its properly formatted or change it if necessary.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Heineman (base prompt, in semi-complex / unnested format)\n",
    "prompt_heineman = open(\"prompts_LLM_annotations/SemiComplex_Prompt_CoT_HM.txt\", \"r\").read()\n",
    "validation_prompt_heineman = open(\"prompts_LLM_annotations/SemiComplex_Prompt_ValidationStep_HM.txt\", \"r\").read()\n",
    "#datamodel = DataModelSemiComplex_HM\n",
    "\n",
    "prompt_heineman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISABLED AFTER SUCCESFUL EXECUTION\n",
    "\n",
    "# # Define list of models.\n",
    "# models = [\n",
    "#     #\"gpt-4o-latest\", \n",
    "#     #\"o1-preview\",\n",
    "#     #\"gpt-4o-mini\",\n",
    "#     #\"claude-3-5-sonnet-20241022\",\n",
    "#     #\"deepseek-ai/deepseek-r1\",\n",
    "#     #\"meta/meta-llama-3-70b-instruct\",\n",
    "#     \"localLLAMA\" #via LM STUDIO\n",
    "# ]\n",
    "\n",
    "# taxID_for_filename = \"PeerSet_Heineman_ZeroShot_L8bn\"\n",
    "\n",
    "# # Call the function\n",
    "# annotations = generate_semicomplex_annotations_for_csv_multi_model(\n",
    "#     csv_file_path=\"../data/salsa_peer_annotations/salsa_peer_data_wikiDE_random.csv\",\n",
    "#     output_dir=\"../data/salsa_annotations/LLM_annotations_output\",\n",
    "#     models=models,\n",
    "#     num_samples=None,        \n",
    "#     seed=42,\n",
    "#     prompt = prompt_heineman,\n",
    "#     validation_prompt = validation_prompt_heineman,\n",
    "#     datamodel_validationstep = DataModelSemiComplex_HM,\n",
    "\n",
    "\n",
    "#     #ID_filter = [6], # allow to filter for specific IDs\n",
    "\n",
    "\n",
    "#     n_fewshot_samples=0, # !!! fewshot samples per sentence pair\n",
    "\n",
    "#     taxName_for_filename = taxID_for_filename\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution - Taxonomy Validation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Data Models for Taxonomies\n",
    "##### Heineman (Semi-Complex Adaptation) \n",
    "-> also used for LLM vs Human Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define allowed categories\n",
    "EditCategory = Literal[\n",
    "    'deletion',\n",
    "    'substitution', \n",
    "    'insertion',\n",
    "    'reorder',\n",
    "    'structure',\n",
    "    'split'\n",
    "]\n",
    "\n",
    "# Define quality types\n",
    "EditQuality = Literal['good', 'bad', 'trivial']\n",
    "\n",
    "# Define significance levels\n",
    "SignificanceLevel = Literal[0, 1, 2, 3]\n",
    "\n",
    "class EditSemiComplex(BaseModel):\n",
    "    category: EditCategory\n",
    "    input_text: List[str] = Field(description=\"The words in the complex (input) sentence affected by the edit\")\n",
    "    output_text: List[str] = Field(description=\"The words in the simplified (output) sentence affected by the edit\")\n",
    "    quality: EditQuality = Field(description=\"Quality of edit: good, bad, or trivial\")\n",
    "    significance: SignificanceLevel = Field(description=\"Significance level: 0 for trivial, 1-3 for good/bad depending on severity (minor: 1, somewhat: 2, a lot: 3)\")\n",
    "\n",
    "class DataModelSemiComplex_HM(BaseModel):\n",
    "    source: str = Field(description=\"The original complex sentence\")\n",
    "    target: str = Field(description=\"The simplified sentence\") \n",
    "    edits: List[EditSemiComplex] = Field(description=\"List of simplification edits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an expert text simplification analyst using the following framework for a research project. \\nYour task is to analyze the differences between an original sentence and its simplified version. Utmost careful work is paramount here.\\n\\nYou are first given some information on the Framework to be used for Text Simplification Error Annotations:\\n\\n<Framework_Information>\\nThe following framework is a comprehensive method for evaluating errors in LLM-generated text simplifications.\\nIt provides a structured approach to annotating and analyzing erroneous changes made between an original text and its simplified version.\\nThe framework govers both good and bad edit types, but you will later focus on the bad edit types.\\n\\nThe framework recognizes 6 primary types of edits:\\nDeletion, Insertion, Substitution, Split, Reordering, and Structural Changes.\\n\\n- Deletion:\\n       - Good Deletion: Did it remove INSIGNIFICANT information (thus improving the sentence)? Example: \"Like so many hyped books before it, The Midnight Library excited me and gave me pause.\" → \"The Midnight Library excited me and gave me pause.\"\\n       - Trivial Deletion: Was it a trivial deletion?\\n       - Bad Deletion: Did it remove SIGNIFICANT information (deleting necessary and relevant content to the sentence\\'s central meaning)? Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many chemicals are increasing in abundance in the lower troposphere.\" (Removing \"volatile organic\")\\n   - Insertion:\\n        - Good Insertions: Adds meaningful, relevant, and correct information. Example: \"Many volatile organic chemicals are increasing...\" → \"Many volatile organic chemicals, which harm our environment, are increasing...\"\\n        - Trivial Insertion: Adds minor modifications that don\\'t significantly affect meaning or complexity. Example: \"How big is the family you cook for?\" → \"How big is the family THAT you cook for?\"\\n        - Bad Insertions:\\n          - Adds information that simply repeats knowledge already contained in the sentence. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals, which are chemicals, are increasing in abundance in the lower troposphere.\"\\n          - Or adds information unrelated to the main idea of the sentence. Example: \"Many volatile organic chemicals are increasing...\" → \"Many volatile organic chemicals, unlike low vapor pressure chemicals, are increasing...\"\\n          - Or adds information that contradicts the original sentence. Example: \"Many volatile organic chemicals are increasing...\" → \"Many volatile organic chemicals, which are decreasing in our troposphere, are increasing...\"\\n          - Or introduces externally verifiable incorrect information. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals are increasing in abundance in the lower troposphere when they decide to.\"\\n\\n   - Substitution:\\n        - Good Substitution: Swaps complex words with equivalent, simpler alternatives, while retaining the same meaning. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals are being seen more in the lower troposphere.\"\\n        - Trivial Substitution:\\n        - Bad Substitution: Deleting significant information by swapping words, or replacing information with (wrong) new information. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals are decreasing in abundance in the lower troposphere.\"\\n\\n   - Split (subdiving a sentence into smaller sentencens).\\n        - Bad Split: Split at an inappropriate location or interrupted the flow of idea. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals are increasing. They are increasing in abundance in the lower troposphere.\"\\n        - Neutral Split: Divides the sentence without significantly affecting readability or meaning\\n        - Good Split: Improves clarity by separating independent pieces of information into distinct sentences. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many volatile organic chemicals are increasing. They are found in abundance in the lower troposphere.\"\\n        Special hint about Split: Only select the \"||\" divider token and, if any, the replaced or changed words from the input sentence - do NOT select the entire new split sentence.\\n\\n   - Reordering:\\n        - Word-level Reorder: Reorganizes modifiers within a phrase\\n            - Bad: Presented a new word order with less clarity within a clause\\n            - Neutral: Reorders words without significantly affecting clarity or meaning\\n            - Good: Presents a new word order that improves clarity within a clause. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"Many organic volatile chemicals are increasing in abundance in the lower troposphere.\"\\n        - Component-level Reorder: Moves clauses or content across a sentence\\n            - Bad: Presents a new clausal order that reduces clarity or disrupts the logical flow of ideas\\n            - Neutral: Reorders components without significantly affecting clarity or meaning\\n            - Good: Presents a new clausal order that improves clarity or the logical flow of ideas. Example: \"Many volatile organic chemicals are increasing in abundance in the lower troposphere.\" → \"In the lower troposphere, many volatile organic chemicals are increasing in abundance.\"\\n\\n   - Structural: \\n        - All of the following are considered structural changes, and each can be considered either a \"good structure\", \"trivial structure\", or \"bad structure\" change:\\n          - Voice Change: Changes between active and passive voice. Example: \"Elevation is not primarily considered by the system.\" → \"The system does not primarily consider elevation.\"\\n          - Part-of-Speech Change: Modifies words\\' derivation or inflection. Example: \"The ability to capture nature scenes has been improving...\" → \"The ability to capture nature scenes has seen improvement...\" Additional example: \"The protesters turned violent when...\" → \"The violent protesters...\"\\n          - Tense Change: Modifies verb modality or tense. \"The governor told reporters he had overseen a productive conversation.\" → \"The governor oversaw a productive conversation.\"\\n          - Grammatical Number Change: Changes between singular and plural or generic and specific. Example: \"Victor had scored that goal against the US in 2011, and another in 2012.\" → \"Victor had scored those goals in 2011 and 2012.\"\\n          - Clausal Change: Modifies predicate structure. Example: \"Donaldson attempted to speak clearly and he was successful.\" → \"Donaldson attempted to speak clearly and successfully.\" Additional example: \"Although it was raining outside, Jobs continued work in his garage.\" → \"Outside it was raining and Jobs continued work in his garage.\"\\n\\nFor each edit, we rate its quality: \\n - either good (did it improve the sentence without deleting significant information) or \\n - bad (deleted significant information while simplifying, or had a negative effect on the sentence simplicity), or\\n - trivial (if no significant effects).\\n\\nFor each edit, we rate its significance as a level out of the following three:\\n   significance levels for negative changes:\\n    - 1: minor (changes, but sentence retains central meaning)\\n    - 2: somewhat (significant changes, but sentence retains central meaning)\\n    - 3: a lot (significant changes, changing or removing the sentence\\'s central meaning or information)\\n    significance levels for positive changes:\\n    - 1: minor (slight improvement in readibility/understandability)\\n    - 2: somewhat (some improvement in improving a sentence\\'s understandability)\\n    - 3: a lot (significant changes in improving a sentence\\'s understandability, while retaining it\\'s core meaning)\\n    \\n    (- 0: trivial)\\n\\n</Framework_Information>\\n\\nNow with this knowledge, follow these steps carefully:\\n\\n<instructions>\\n1. Input: You will be presented with two sentences:\\n<original_sentence>\\n{{ORIGINAL_SENTENCE}}\\n</original_sentence>\\n\\n<simplified_sentence>\\n{{SIMPLIFIED_SENTENCE}}\\n</simplified_sentence>\\n\\n2. Identify Changes:\\nList all changes you observe between the original and simplified sentences. \\nFor each change, specify the affected words as a string (e.g. \"The quick brown\").\\nList them all in a <identified_changes> section.\\nImportant: Try to avoid overlapping edits, meaning a given word should ideally only be present in one identified edit and edits should not overlap.\\nAnd try to keep an edit to its smallest possible size (e.g., split up bigger edits into their components when sensible instead of marking half of a sentence as one big edit).\\nVery important: Every single edit MUST have associated word(s) or spans of words, even splits or structure changes. Never indicate an edit operation that has not at least either an input or output text part associated with it.\\n\\n3. Categorize Changes:\\nFor each change:\\nIs it an error or bad edit? If yes, continue. Otherwise, drop this change.\\nIf Error: categorize its type according to the framework. (Ignore good edits in your final output, only bad edits are important in this analysis.)\\nDetermine if it\\'s a Deletion, Insertion, Substitution, Reordering, Split, or Structural change. \\nList them all in a <categorized_changes> section.\\n\\n4. Analyze quality and rate significance:\\nFor each categorized change, analyze its quality and significance.\\nAs the remaining changes should only be errors (bad edits), their quality is automatically \"bad\". Then rate the significance of each change on a scale of minor, somewhat, a lot. Justify each rating based on the framework guidelines.\\nList them all in a <rating_changes> section.\\n\\n5. Detect Errors:\\nExamine the simplified sentence for any potential errors, such as coreference issues or grammar and fluency problems. \\nList any additional errors you find in a <errors> section.\\n\\n6. Generate OUTPUT CSV Structure:\\nBased on your analysis and all the information you created, create a CSV structure for the analyzed sentence pair that follows the format of the examples supplied below.\\nCreate one row for each edit.\\n\\nBetween <OUTPUT> and </OUTPUT>, output only the CSV lines. Do not include headings, bullet points, or explanatory text. \\nThe first line inside <OUTPUT>...</OUTPUT> must be the header\\n\\nExample output section:\\n<OUTPUT>\\ninput_segment,output_segment,edit_type,quality,significance\\n\"brown\",\"dark\",substitution,bad,minor\\n...\\n</OUTPUT>\\n\\n\\n7. Review and Refine:\\nReview the erroneous edits you\\'ve identified and properly formatted. Ensure all relevant changes are accurately represented and all required fields are present. \\nTry avoiding overlapping edits. Keep edits as tight as possible, affecting as few worlds as possible (NOT marking entire clauses when not necessary).\\n\\nUse the examples below and the framework guidelines as help. Make any necessary adjustments.\\n</instructions>\\n\\n<examples>\\n<TODO INSERT EXAMPLE>\\n</examples>\\n\\nRemember to be thorough in your analysis and think step by step. Verify your output format at the end, to validate its properly formatted or change it if necessary.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Heineman (for comparison):\n",
    "prompt_heineman = open(\"prompts_LLM_annotations/SemiComplex_Prompt_CoT_HM.txt\", \"r\").read()\n",
    "validation_prompt_heineman = open(\"prompts_LLM_annotations/SemiComplex_Prompt_ValidationStep_HM.txt\", \"r\").read()\n",
    "datamodel = DataModelSemiComplex_HM\n",
    "\n",
    "prompt_heineman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted data saved to: ../data/LLM_annotations/LLM_annotations_N50_Heineman_GPT4o_FULL_LEVELSformat.json\n",
      "Converted data saved to: ../data/LLM_annotations/LLM_annotations_N50_Heineman_ClaudeSonnet_FULL_LEVELSformat.json\n",
      "Converted data saved to: ../data/LLM_annotations/LLM_annotations_N50_Heineman_LLAMA8b_FULL_LEVELSformat.json\n"
     ]
    }
   ],
   "source": [
    "# function to convert heineman structure to a level1, level2, level3 structure\n",
    "\n",
    "import json\n",
    "\n",
    "def convert_old_to_new_format(old_json_path: str, new_json_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Reads a JSON file in the 'old' data format and converts it into a\n",
    "    new data format with level1, level2, and level3 fields.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Load the old JSON data\n",
    "    with open(old_json_path, 'r', encoding='utf-8') as infile:\n",
    "        old_data = json.load(infile)\n",
    "    \n",
    "    new_data = []\n",
    "\n",
    "    # 2. Iterate over each record in the old data\n",
    "    for record in old_data:\n",
    "        # Prepare the new record structure\n",
    "        new_record = {\n",
    "            \"source\": record[\"source\"],\n",
    "            \"target\": record[\"target\"],\n",
    "            \"metadata\": record.get(\"metadata\", {}),\n",
    "            \"edits\": []\n",
    "        }\n",
    "        \n",
    "        # Carry over _thresh_id if it exists\n",
    "        if \"_thresh_id\" in record:\n",
    "            new_record[\"_thresh_id\"] = record[\"_thresh_id\"]\n",
    "\n",
    "        # 3. Convert each edit from the old format to the new format\n",
    "        for edit in record[\"edits\"]:\n",
    "            new_edit = {\n",
    "                # level1 is just the old 'category'\n",
    "                \"edit_type_level1\": edit[\"category\"],\n",
    "                \n",
    "                # level2 is a combination of old 'quality' and 'category'\n",
    "                \"edit_type_level2\": f\"{edit['quality']} {edit['category']}\",\n",
    "                \n",
    "                # level3 is the old 'significance'\n",
    "                \"edit_type_level3\": str(edit.get(\"significance\", [])),\n",
    "                \n",
    "                # Keep the input_text and output_text as is\n",
    "                \"input_text\": edit.get(\"input_text\", []),\n",
    "                \"output_text\": edit.get(\"output_text\", []),\n",
    "\n",
    "                # with the other fields set to None\n",
    "                \"orthogonal_data\": {\n",
    "                    \"severity\": str(edit.get(\"significance\", [])),\n",
    "                    \"scope\": None,\n",
    "                    \"domain_sensitivity\": None,\n",
    "                    \"factual_dependence\": None,\n",
    "                    \"polarity_switch\": None,\n",
    "                    \"simplification_direction\": None\n",
    "                }\n",
    "            }\n",
    "            new_record[\"edits\"].append(new_edit)\n",
    "\n",
    "        new_data.append(new_record)\n",
    "    \n",
    "    # 4. Save the new data structure to the specified file\n",
    "    with open(new_json_path, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(new_data, outfile, indent=4, ensure_ascii=False)\n",
    "    print(f\"Converted data saved to: {new_json_path}\")\n",
    "\n",
    "\n",
    "files_to_convert = [\n",
    "    (\"../data/LLM_annotations/LLM_annotations_N50_Heineman_GPT4o_FULL.json\", \"../data/LLM_annotations/LLM_annotations_N50_Heineman_GPT4o_FULL_LEVELSformat.json\"),\n",
    "    (\"../data/LLM_annotations/LLM_annotations_N50_Heineman_ClaudeSonnet_FULL.json\", \"../data/LLM_annotations/LLM_annotations_N50_Heineman_ClaudeSonnet_FULL_LEVELSformat.json\"),\n",
    "    (\"../data/LLM_annotations/LLM_annotations_N50_Heineman_LLAMA8b_FULL.json\", \"../data/LLM_annotations/LLM_annotations_N50_Heineman_LLAMA8b_FULL_LEVELSformat.json\"),\n",
    "   \n",
    "]\n",
    "\n",
    "for old_file, new_file in files_to_convert:\n",
    "    convert_old_to_new_format(old_file, new_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Huidrom & Belz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List, Literal, Union\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define Level 1 Edit Types (Main categories)\n",
    "EditTypeLevel1 = Literal[\"Omission\", \"Addition\", \"Substitution\"]\n",
    "\n",
    "# Define Level 2 Edit Types (Sub-categories)\n",
    "EditTypeLevel2 = Literal[\n",
    "    \"Duplication\", \"Other\",  # For Addition\n",
    "    \"Should Have Been Left Verbatim\", \"Should Not Have Been Left Verbatim\", \"Lexical Error\", \"Error in Input\", \"Reordering\", \"Other Wrongly Rendered Input\"  # For Substitution\n",
    "]\n",
    "\n",
    "# Define Level 3 Edit Types (Sub-sub-categories, only relevant for Error in Input)\n",
    "EditTypeLevel3 = Literal[\n",
    "    \"Disambiguation Error\", \"Multi-Word Expression Error\", \"Other Wrong Lexical Choice\"\n",
    "]\n",
    "\n",
    "# Orthogonal Error Type: Deviation Types\n",
    "MeaningDeviation = Literal[\n",
    "    \"NE Deviation\", \"Polarity Deviation\", \"Numerical Deviation\", \"Other Meaning Deviation\"\n",
    "]\n",
    "\n",
    "# Orthogonal Error Type: Context vs. Function\n",
    "ContextFunctionType = Literal[\"Content Words\", \"Function Words\"]\n",
    "\n",
    "# Orthogonal Error Type: Number of Words\n",
    "NumWordsType = Literal[\"Single Word\", \"Multiple Words\"]\n",
    "\n",
    "# Orthogonal Error Type: Severity\n",
    "SeverityType = Literal[\"Major\", \"Minor\"]\n",
    "\n",
    "# Orthogonal Error Type: Syntactic Category\n",
    "SyntacticCategory = Literal[\"Subject\", \"Object\", \"Other\"]\n",
    "\n",
    "class OrthogonalData(BaseModel):\n",
    "    meaning_deviation: Optional[MeaningDeviation] = None\n",
    "    context_function: Optional[ContextFunctionType] = None\n",
    "    num_words: NumWordsType\n",
    "    severity: SeverityType\n",
    "    syntactic_category: Optional[SyntacticCategory] = None\n",
    "\n",
    "\n",
    "class EditMaximallyMerged(BaseModel):\n",
    "    edit_type_level1: EditTypeLevel1\n",
    "    edit_type_level2: Optional[EditTypeLevel2] = None\n",
    "    edit_type_level3: Optional[EditTypeLevel3] = None\n",
    "    input_text: List[str] = Field(description=\"Words in the complex (input) sentence affected by the edit\")\n",
    "    output_text: List[str] = Field(description=\"Words in the simplified (output) sentence affected by the edit\")\n",
    "    orthogonal_data: OrthogonalData\n",
    "\n",
    "\n",
    "class DataModelMaximallyMerged_BH(BaseModel):\n",
    "    source: str = Field(description=\"The original complex sentence\")\n",
    "    target: str = Field(description=\"The simplified sentence\")\n",
    "    edits: List[EditMaximallyMerged] = Field(description=\"List of identified content/meaning errors according to the Maximally Merged Taxonomy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_meta_huidrom = open(\"prompts_LLM_annotations/SemiComplex_Prompt_CoT_HuidromBelz.txt\", \"r\").read()\n",
    "validation_prompt_meta_huidrom = open(\"prompts_LLM_annotations/SemiComplex_Prompt_ValidationStep_HuidromBelz.txt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MB2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# === Level 1 Categories ===\n",
    "EditTypeLevel1 = Literal[\"Content / Meaning Errors\", \"Form / Fluency Errors\"]\n",
    "\n",
    "# === Level 2 Categories ===\n",
    "EditTypeLevel2 = Literal[\n",
    "    # Content / Meaning Errors\n",
    "    \"Omission\", \"Addition\", \"Substitution\",\n",
    "    # Form / Fluency Errors\n",
    "    \"Coherence and Structural Issues\", \"Syntactic Errors\", \"Stylistic Errors\"\n",
    "]\n",
    "\n",
    "# === Level 3 Subtypes ===\n",
    "EditTypeLevel3 = Literal[\n",
    "    # Omission (under Content / Meaning Errors)\n",
    "    \"Essential Omission\", \"Contextual Omission\",\n",
    "\n",
    "    # Addition (under Content / Meaning Errors)\n",
    "    \"Unnecessary Expansion\", \"Factual Hallucination\", \"Repetitive Addition\",\n",
    "\n",
    "    # Substitution (under Content / Meaning Errors)\n",
    "    \"Lexical Inaccuracy / Semantic Drift\", \"Factual Distortion\", \"Lack of Simplicity / Lexical Complexity\", \"Coreference / Anaphora Resolution\",\n",
    "\n",
    "    # Coherence and Structural Issues (under Form / Fluency Errors)\n",
    "    \"Awkward Phrasing\", \"Bad Structure / Split\",\n",
    "\n",
    "    # Syntactic Errors (under Form / Fluency Errors)\n",
    "    \"Subject-Verb Agreement Error\", \"Tense Inconsistency\", \"Punctuation Errors\",\n",
    "\n",
    "    # Stylistic Errors (under Form / Fluency Errors)\n",
    "    \"Genre / Tone Misalignment\"\n",
    "]\n",
    "\n",
    "# === Orthogonal Dimension Types ===\n",
    "SeverityType = Literal[\"Minor\", \"Major\", \"Critical\"]\n",
    "ScopeType = Literal[\"Word\", \"Phrase\", \"Clause\", \"Sentence\"]\n",
    "DomainSensitivityType = Literal[\"Generic\", \"Domain-Specific\"]\n",
    "FactualDependenceType = Literal[\"Requires External Knowledge\", \"Self-Contained\"]\n",
    "PolaritySwitchType = Literal[\"Polarity Switch\", None]\n",
    "SimplificationDirectionType = Literal[\"Too Complex\", \"Too Simple\", None]\n",
    "\n",
    "class OrthogonalData(BaseModel):\n",
    "    severity: SeverityType\n",
    "    scope: ScopeType\n",
    "    domain_sensitivity: Optional[DomainSensitivityType] = None\n",
    "    factual_dependence: Optional[FactualDependenceType] = None\n",
    "    polarity_switch: Optional[PolaritySwitchType] = None\n",
    "    simplification_direction: Optional[SimplificationDirectionType] = None\n",
    "\n",
    "\n",
    "class EditHierarchical(BaseModel):\n",
    "    edit_type_level1: EditTypeLevel1\n",
    "    edit_type_level2: EditTypeLevel2\n",
    "    edit_type_level3: Optional[EditTypeLevel3] = None\n",
    "    input_text: List[str] = Field(description=\"Words in the complex (input) sentence affected by the edit\")\n",
    "    output_text: List[str] = Field(description=\"Words in the simplified (output) sentence affected by the edit\")\n",
    "    orthogonal_data: OrthogonalData\n",
    "\n",
    "\n",
    "class DataModelHierarchicalTaxonomy_MB(BaseModel):\n",
    "    source: str = Field(description=\"The original complex sentence\")\n",
    "    target: str = Field(description=\"The simplified sentence\")\n",
    "    edits: List[EditHierarchical] = Field(description=\"List of identified content/meaning and fluency/form errors according to the hierarchical taxonomy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are an expert text simplification analyst using the following framework for a research project. \\nYour task is to analyze the differences between an original sentence and its simplified version. Utmost careful work is paramount here.\\n\\nYou are first given some information on the Framework to be used for Text Simplification Error Annotations:\\n\\n<Framework_Information>\\nThe following framework is a comprehensive method for evaluating errors in LLM-generated text simplifications.\\nIt provides a structured approach to annotating and analyzing erroneous changes made between an original text and its simplified version.\\nThe taxonomy is designed to be domain-agnostic and captures both content/meaning errors and fluency/form errors, while allowing for adjustments to the level of detail through its hierarchical structure (3 levels).\\n\\nThe framework recognizes the following primary error types and sub-types:\\n1. Content / Meaning Errors (Errors impacting factual content, semantics, or meaning):\\n\\tL2: Omission: Information present in the original sentence is missing in the simplified version.\\n\\t\\t•\\tL3: Essential Omission: Critical data (e.g., numerical values, key descriptors, or qualifiers) that is necessary for understanding the core meaning is lost.\\n\\t\\t•\\tL3: Contextual Omission: Background or contextual details are omitted. While the core meaning may remain intact, nuance and tone are affected.\\n\\tL2: Addition: Unnecessary or incorrect information is added to the simplified version.\\n\\t\\t•\\tL3: Unnecessary Expansion: Factually accurate details are added that do not contribute to the core message and may distract from it.\\n\\t\\t•\\tL3: Factual Hallucination: Incorrect or fabricated information is inserted, misrepresenting the original facts.\\n\\t\\t•\\tL3: Repetitive Addition: Redundant information is added (e.g., restating something already present).\\n\\tL2: Substitution: Content is replaced with incorrect, misleading, or unnecessarily complex alternatives.\\n\\t\\t•\\tL3: Lexical Inaccuracy / Semantic Drift: A word/phrase is replaced with one that is semantically incorrect or changes the meaning.\\n\\t\\t•\\tL3: Factual Distortion: Factual elements (such as numbers, names, or events) are altered, resulting in a misrepresentation of the original.\\n\\t\\t•\\tL3: Lack of Simplicity / Lexical Complexity: A simpler expression is replaced by a more complex or technical term that does not suit the purpose of simplification.\\n\\t\\t•\\tL3: Coreference / Anaphora Resolution: Errors in resolving pronouns or references that lead to confusion about the entity being discussed.\\n\\n2. Form / Fluency Errors (Errors affecting the text’s readability, fluency, or grammatical correctness):\\n\\tL2: Coherence and Structural Issues: Logical flow, sentence structure, or overall coherence is disrupted.\\n\\t\\t•\\tL3: Awkward Phrasing: Unnatural, clunky, or forced expressions disrupt fluency.\\n\\t\\t•\\tL3: Bad Structure / Split: Sentences are reordered or split unnaturally, harming readability and disrupting the intended narrative flow.\\n\\tL2: Syntactic Errors: Grammatical issues impair the text’s correctness and clarity.\\n\\t\\t•\\tL3: Subject-Verb Agreement Error: Subject and verb disagree in number or person.\\n\\t\\t•\\tL3: Tense Inconsistency: Tense shifts within the same context cause confusion.\\n\\t\\t•\\tL3: Punctuation Errors: Incorrect/missing punctuation reduces clarity.\\n\\tL2: Stylistic Errors: The tone, style, or genre becomes inconsistent with the original or the intended audience.\\n\\t\\t•\\tL3: Genre/Tone Misalignment: The style or tone does not match the context or audience.\\n\\n3. Orthogonal Dimensions (Applied Across All Error Types):\\nThese additional attributes refine the primary error categories:\\n\\t•\\tSeverity: Minor, Major, Critical \\n\\t\\t(Minor: The error has little to no impact on comprehension (e.g., a slight punctuation mistake). Major: The error leads to noticeable confusion or misrepresentation of key content. Critical: The error severely alters the intended meaning or factual accuracy.)\\n\\t•\\tScope: Word, Phrase, Clause, Sentence affected/covered by the edit\\n\\t•\\tDomain Sensitivity: Generic, Domain-Specific (Does the error disproportionately impact specialized content like medical or legal text, making it more critical there?)\\n\\t•\\tFactual Dependence: Requires External Knowledge, Self-Contained (Does identifying the error require external world knowledge or is it inferable from the text alone?)\\n\\t•\\tPolarity Switch / Contradiction: Whether the meaning is inverted or contradicted (e.g., “safe” → “dangerous”).\\n\\t•\\tSimplification Direction: Too Complex, Too Simple (Did the edit make the text harder to read by introducing unnecessary jargon or complexity; or oversimplified the meaning?)\\n\\nAdditional Guidelines:\\n\\t•\\tAtomicity and Non-Overlap:\\nEach edit should be as atomic as possible. Ensure that each identified change captures the smallest meaningful unit (word, phrase, clause) without overlapping with other edits. Consider using a decision tree:\\n\\t1.\\tDoes the change affect factual content? → Consider Content / Meaning Errors.\\n\\t2.\\tIs the change only in structure or grammar? → Consider Form / Fluency Errors.\\n\\t3.\\tIf both apply, determine the primary impact (factual misrepresentation vs. readability issue).\\n\\t\\n</Framework_Information>\\n\\nNow with this knowledge, follow these steps carefully:\\n\\n<instructions>\\n1. Input: You will be presented with two sentences:\\n<original_sentence>\\n{{ORIGINAL_SENTENCE}}\\n</original_sentence>\\n\\n<simplified_sentence>\\n{{SIMPLIFIED_SENTENCE}}\\n</simplified_sentence>\\n\\n2. Identify Changes:\\nList all changes you observe between the original and simplified sentences. \\nFor each change, specify the affected words as a string (e.g. \\'The quick brown\\').\\nList them all in a <identified_changes> section.\\nImportant: Try to avoid overlapping edits, meaning a given word should ideally only be present in one identified edit and edits should not overlap.\\nAnd try to keep an edit to its smallest possible size (e.g., split up bigger edits into their components when sensible instead of marking half of a sentence as one big edit).\\nVery important: Every single edit MUST have associated word(s) or spans of words. Never indicate an edit operation that has not at least either an input or output text part associated with it.\\n\\n3. Categorize Changes\\n\\nFor each change: \\n\\t•\\tIs it an error or bad edit? If yes, continue. Otherwise, drop this change.\\n\\t•\\tAssign Level 1 error type (Content/Meaning or Form/Fluency).\\n\\t•\\tAssign Level 2 sub-type.\\n\\t•\\tIf applicable, specify Level 3 sub-type.\\n\\t•\\tAssign orthogonal error attributes as necessary:\\n\\t\\t•\\tSeverity\\n\\t\\t•\\tScope\\n\\t\\t•\\tDomain Sensitivity\\n\\t\\t•\\tFactual Dependence\\n\\t\\t•\\tPolarity Switch / Contradiction\\n\\t\\t•\\tSimplification Direction\\n\\n4. Generate OUTPUT CSV Structure:\\nBased on your analysis and all the information you created, create a CSV structure for the analyzed sentence pair that follows the format of the examples supplied below.\\nCreate one row for each edit.\\n\\nBetween <OUTPUT> and </OUTPUT>, output only the CSV lines. Do not include headings, bullet points, or explanatory text. \\nThe first line inside <OUTPUT>...</OUTPUT> must be the header\\n\\nExample output section:\\n<OUTPUT>\\ninput_segment,output_segment,edit_type_level1,edit_type_level2,edit_type_level3,orthogonal_types\\n\"quick brown\",\"fast dark\",\"Content / Meaning Errors\",\"Substitution\",\"Lexical Inaccuracy / Semantic Drift\",\"severity:Major;scope:Phrase\"\\n\"\",\"which harm the environment\",\"Content / Meaning Errors\",\"Addition\",\"Unnecessary Expansion\",\"severity:Minor;scope:Phrase\"\\n</OUTPUT>\\n\\nHint: Even if the specific edit type does not utilize a given edit_type_level, return it empty.\\n\\n\\n5. Review and Refine:\\nReview the erroneous edits you\\'ve identified and properly formatted. Ensure all relevant changes are accurately represented and all required fields are present. \\nTry avoiding overlapping edits. Keep edits as tight as possible, affecting as few worlds as possible (NOT marking entire clauses when not necessary).\\n\\nUse the examples below and the framework guidelines as help. Make any necessary adjustments.\\n</instructions>\\n\\n<examples>\\n<TODO INSERT EXAMPLE>\\n</examples>\\n\\nRemember to be thorough in your analysis and think step by step. Verify your output format at the end, to validate its properly formatted or change it if necessary.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_mb2025 = open(\"prompts_LLM_annotations/SemiComplex_Prompt_CoT_MB2025.txt\", \"r\").read()\n",
    "validation_prompt_mb2025 = open(\"prompts_LLM_annotations/SemiComplex_Prompt_ValidationStep_MB2025.txt\", \"r\").read()\n",
    "\n",
    "\n",
    "prompt_mb2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/TS_datasets/taxonomy_validation_subset_n50.csv\", encoding='mac_roman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of models to use as annotators\n",
    "models = [\n",
    "    \"gpt-4o-latest\", \n",
    "    \"claude-3-5-sonnet-20241022\",\n",
    "    \"localLLAMA\" #via LM STUDIO\n",
    "]\n",
    "\n",
    "taxID_for_filename = \"MB2025\"\n",
    "\n",
    "# Call the function (adjust the prompt strings and datamodel as needed)\n",
    "# (DISABLED AFTER SUCCESSFUL EXECUTION)\n",
    "\n",
    "# annotations = generate_semicomplex_annotations_for_csv_multi_model(\n",
    "#     csv_file_path=\"../data/TS_datasets/taxonomy_validation_subset_n50.csv\",\n",
    "#     output_dir=\"../data/salsa_annotations/LLM_annotations_output\",\n",
    "#     models=models,\n",
    "#     num_samples=None,        \n",
    "#     seed=42,\n",
    "#     prompt = prompt_mb2025,\n",
    "#     validation_prompt = validation_prompt_mb2025,\n",
    "#     datamodel_validationstep = DataModelHierarchicalTaxonomy_MB,\n",
    "#     n_fewshot_samples=0, # DO NOT USE FEWSHOT when using a custom taxonomy !\n",
    "#     taxName_for_filename = taxID_for_filename\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
